{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1d7535-f0e0-4d07-8327-674025f40ed8",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66bbd0dc-05b8-415d-bc65-2653a3de5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d9a5f-be13-4ca6-bfc1-aa96d31e856d",
   "metadata": {},
   "source": [
    "# Importando DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "340fc463-a980-445a-be19-52c03064db3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>662.28</td>\n",
       "      <td>39.10</td>\n",
       "      <td>-188.55</td>\n",
       "      <td>0.246978</td>\n",
       "      <td>761</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>3.523703</td>\n",
       "      <td>167326</td>\n",
       "      <td>33441.06</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>94.611429</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.55</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>78.93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>23</td>\n",
       "      <td>346.08</td>\n",
       "      <td>30.41</td>\n",
       "      <td>-102.10</td>\n",
       "      <td>2.430952</td>\n",
       "      <td>42</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>3.389618</td>\n",
       "      <td>9907</td>\n",
       "      <td>18858.77</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>25.525000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>86.520000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.84</td>\n",
       "      <td>-56.16</td>\n",
       "      <td>0.150968</td>\n",
       "      <td>372</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63544</td>\n",
       "      <td>1164.11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>18</td>\n",
       "      <td>87.56</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-94.50</td>\n",
       "      <td>0.412664</td>\n",
       "      <td>229</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.926561</td>\n",
       "      <td>50089</td>\n",
       "      <td>1786.26</td>\n",
       "      <td>0.049019</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>87.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1435.68</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-848.40</td>\n",
       "      <td>0.589167</td>\n",
       "      <td>1440</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>1.692221</td>\n",
       "      <td>371185</td>\n",
       "      <td>2745.78</td>\n",
       "      <td>0.522868</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>68.365714</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>436.85</td>\n",
       "      <td>6.80</td>\n",
       "      <td>-82.15</td>\n",
       "      <td>0.238116</td>\n",
       "      <td>345</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>5.317712</td>\n",
       "      <td>18776</td>\n",
       "      <td>959.57</td>\n",
       "      <td>0.455256</td>\n",
       "      <td>20.537500</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>109.212500</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>-16.80</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>112</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6500</td>\n",
       "      <td>6692.13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1027.86</td>\n",
       "      <td>79.76</td>\n",
       "      <td>-110.56</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>288</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>9.845402</td>\n",
       "      <td>19075</td>\n",
       "      <td>3611.20</td>\n",
       "      <td>0.284631</td>\n",
       "      <td>8.030769</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>79.066154</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2876.01</td>\n",
       "      <td>3.68</td>\n",
       "      <td>-596.32</td>\n",
       "      <td>0.265251</td>\n",
       "      <td>2247</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>4.825358</td>\n",
       "      <td>490191</td>\n",
       "      <td>2324.27</td>\n",
       "      <td>1.237382</td>\n",
       "      <td>31.369474</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>151.368947</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0     200.0         2    662.28     39.10   -188.55  0.246978       761   \n",
       "1     150.0         3      0.00    149.55     -0.45  0.150000         3   \n",
       "2      50.0        23    346.08     30.41   -102.10  2.430952        42   \n",
       "3     100.0        22      0.00     43.84    -56.16  0.150968       372   \n",
       "4      50.0        18     87.56     -3.05    -94.50  0.412664       229   \n",
       "5     850.0         9   1435.68      1.60   -848.40  0.589167      1440   \n",
       "6      50.0         1    436.85      6.80    -82.15  0.238116       345   \n",
       "7       0.0         0      0.00     -6.50    -16.80  0.150000       112   \n",
       "8     100.0        11   1027.86     79.76   -110.56  0.362500       288   \n",
       "9     600.0        21   2876.01      3.68   -596.32  0.265251      2247   \n",
       "\n",
       "   feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "0  0.004548  3.523703    167326   33441.06   0.019804  26.850000   0.009198   \n",
       "1  0.037975  0.000000        79      78.93   0.000000   0.000000   0.000000   \n",
       "2  0.004239  3.389618      9907   18858.77   0.018351  25.525000   0.095238   \n",
       "3  0.005854  0.000000     63544    1164.11   0.000000   0.000000   0.000000   \n",
       "4  0.004572  0.926561     50089    1786.26   0.049019  94.500000   0.004367   \n",
       "5  0.003879  1.692221    371185    2745.78   0.522868  40.400000   0.014583   \n",
       "6  0.018375  5.317712     18776     959.57   0.455256  20.537500   0.011594   \n",
       "7  0.017231  0.000000      6500    6692.13   0.000000   0.000000   0.000000   \n",
       "8  0.015098  9.845402     19075    3611.20   0.284631   8.030769   0.045139   \n",
       "9  0.004584  4.825358    490191    2324.27   1.237382  31.369474   0.008456   \n",
       "\n",
       "    feature14  feature15  target  \n",
       "0   94.611429          7       0  \n",
       "1    0.000000          0       1  \n",
       "2   86.520000          4       0  \n",
       "3    0.000000          0       1  \n",
       "4   87.560000          1       0  \n",
       "5   68.365714         21       1  \n",
       "6  109.212500          4       1  \n",
       "7    0.000000          0       0  \n",
       "8   79.066154         13       0  \n",
       "9  151.368947         19       1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_SIN492 = pd.read_csv(\"dataset_SIN492.parquet.csv\")\n",
    "base_SIN492.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b03b81-4856-433c-bce3-e661666ea435",
   "metadata": {},
   "source": [
    "# Características do Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ac10b04-e5f6-4357-8a61-8e869811e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = base_SIN492.iloc[:, :15].values\n",
    "saidas = base_SIN492.iloc[:, 16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46dc91f8-f882-4a4b-bf61-1a2ce8c1a0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 15)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape\n",
    "#saidas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8f065-9cb5-4d54-9f02-f2e1e7194728",
   "metadata": {},
   "source": [
    "# Normalizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "efc52477-06ce-4c3e-806d-25214c1d29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "entradas = normalizador.fit_transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "874a0de8-adf0-4d18-a6b4-bf78b7c04ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd618a-ba18-4d4a-ae30-8a7072681e13",
   "metadata": {},
   "source": [
    "# Divisão do Conjunto de Dados - 20% Teste e 80% Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f267b5e7-d90b-4439-9cc0-1fd06f5a1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradasTrain, entradasTest, valoresSaidaTrain, valoresSaidaTest = train_test_split(entradas, saidas, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4fca3db3-2b8a-4974-b5ec-ccddd89e2920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Dados de Treino: 372\n",
      "Quantidade de Dados de Teste: 94\n",
      "Quantidade de Dados de Treino e dos atributos: (372, 15)\n",
      "Quantidade de Dados de Teste e dos atributos (94, 15)\n",
      "Quantidade de Saidas de Treino e coluna: (372,)\n",
      "Quantidade de Saidas de Teste e coluna: (94,)\n",
      "min:  0\n",
      "max:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de Dados de Treino:\" ,len(entradasTrain))\n",
    "print(\"Quantidade de Dados de Teste:\" ,len(entradasTest))\n",
    "\n",
    "print(\"Quantidade de Dados de Treino e dos atributos:\" ,entradasTrain.shape)\n",
    "print(\"Quantidade de Dados de Teste e dos atributos\" ,entradasTest.shape)\n",
    "\n",
    "print(\"Quantidade de Saidas de Treino e coluna:\" ,valoresSaidaTrain.shape)\n",
    "print(\"Quantidade de Saidas de Teste e coluna:\" ,valoresSaidaTest.shape)\n",
    "\n",
    "print(\"min: \", valoresSaidaTrain.min())\n",
    "print(\"max: \", valoresSaidaTrain.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65f8db-9cd8-41f1-949d-b4b3bd0fa4b6",
   "metadata": {},
   "source": [
    "# Salvar os pesos do modelo periodicamnte durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b6edf1c-5c70-421c-8b40-e4ef9bf2e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras as k\n",
    "\n",
    "# Novo checkpoint h5 -----------------------------------------\n",
    "checkpoint_path = \"./SIN492-{epoch:04d}.hdf5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Novo cp_callback h5 -------------------------------------------\n",
    "cp_callback = k.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37cc89-31e6-4d16-9721-5a7ec137fe28",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42e00dd0-8e81-44ba-8907-9b5018642b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddb8c4-8031-42f5-a5c6-f92a092cbdd3",
   "metadata": {},
   "source": [
    "# Definir Modelo de Rede Neural - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50728639-50c7-4ec9-a4b7-8c59f576bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(15,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec77dc-f581-4623-90fc-a38f13c28205",
   "metadata": {},
   "source": [
    "# Compilar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a52dc43f-31c7-4302-8b39-1e8833eea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853877d-b6cc-4634-bcc0-3680dc1a808c",
   "metadata": {},
   "source": [
    "# Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b181e209-a329-46b2-a899-3b6748c785c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/3 [=========>....................] - ETA: 8s - loss: 0.9532 - accuracy: 0.5625\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47872, saving model to .\\SIN492-0001.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 788ms/step - loss: 0.8732 - accuracy: 0.5591 - val_loss: 0.6854 - val_accuracy: 0.4787\n",
      "Epoch 2/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8295 - accuracy: 0.5312\n",
      "Epoch 2: val_accuracy improved from 0.47872 to 0.48936, saving model to .\\SIN492-0002.hdf5\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.8291 - accuracy: 0.5457 - val_loss: 0.6839 - val_accuracy: 0.4894\n",
      "Epoch 3/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7472 - accuracy: 0.5938\n",
      "Epoch 3: val_accuracy improved from 0.48936 to 0.55319, saving model to .\\SIN492-0003.hdf5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.8207 - accuracy: 0.5726 - val_loss: 0.6827 - val_accuracy: 0.5532\n",
      "Epoch 4/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7675 - accuracy: 0.5391\n",
      "Epoch 4: val_accuracy improved from 0.55319 to 0.65957, saving model to .\\SIN492-0004.hdf5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.8005 - accuracy: 0.5538 - val_loss: 0.6818 - val_accuracy: 0.6596\n",
      "Epoch 5/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7745 - accuracy: 0.5938\n",
      "Epoch 5: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.8061 - accuracy: 0.5430 - val_loss: 0.6812 - val_accuracy: 0.6383\n",
      "Epoch 6/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8239 - accuracy: 0.5156\n",
      "Epoch 6: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.7892 - accuracy: 0.5645 - val_loss: 0.6806 - val_accuracy: 0.6383\n",
      "Epoch 7/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7780 - accuracy: 0.5547\n",
      "Epoch 7: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7846 - accuracy: 0.6102 - val_loss: 0.6801 - val_accuracy: 0.6170\n",
      "Epoch 8/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8041 - accuracy: 0.5703\n",
      "Epoch 8: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7465 - accuracy: 0.5591 - val_loss: 0.6795 - val_accuracy: 0.5957\n",
      "Epoch 9/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6817 - accuracy: 0.6250\n",
      "Epoch 9: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7484 - accuracy: 0.5806 - val_loss: 0.6790 - val_accuracy: 0.5851\n",
      "Epoch 10/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8054 - accuracy: 0.4922\n",
      "Epoch 10: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.7611 - accuracy: 0.5565 - val_loss: 0.6786 - val_accuracy: 0.5957\n",
      "Epoch 11/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7753 - accuracy: 0.5547\n",
      "Epoch 11: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8031 - accuracy: 0.5484 - val_loss: 0.6782 - val_accuracy: 0.5957\n",
      "Epoch 12/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7873 - accuracy: 0.5703\n",
      "Epoch 12: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7785 - accuracy: 0.5914 - val_loss: 0.6778 - val_accuracy: 0.5957\n",
      "Epoch 13/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7612 - accuracy: 0.5781\n",
      "Epoch 13: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7466 - accuracy: 0.5672 - val_loss: 0.6775 - val_accuracy: 0.6170\n",
      "Epoch 14/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7080 - accuracy: 0.6094\n",
      "Epoch 14: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7604 - accuracy: 0.5806 - val_loss: 0.6774 - val_accuracy: 0.6383\n",
      "Epoch 15/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7129 - accuracy: 0.5703\n",
      "Epoch 15: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7368 - accuracy: 0.5806 - val_loss: 0.6773 - val_accuracy: 0.6383\n",
      "Epoch 16/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7405 - accuracy: 0.5938\n",
      "Epoch 16: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7214 - accuracy: 0.6048 - val_loss: 0.6771 - val_accuracy: 0.6277\n",
      "Epoch 17/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7091 - accuracy: 0.5469\n",
      "Epoch 17: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.7297 - accuracy: 0.5591 - val_loss: 0.6770 - val_accuracy: 0.6277\n",
      "Epoch 18/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6910 - accuracy: 0.6016\n",
      "Epoch 18: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.7230 - accuracy: 0.5968 - val_loss: 0.6769 - val_accuracy: 0.6277\n",
      "Epoch 19/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7159 - accuracy: 0.5469\n",
      "Epoch 19: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.7433 - accuracy: 0.5484 - val_loss: 0.6767 - val_accuracy: 0.6277\n",
      "Epoch 20/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7842 - accuracy: 0.5938\n",
      "Epoch 20: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7372 - accuracy: 0.5941 - val_loss: 0.6766 - val_accuracy: 0.6277\n",
      "Epoch 21/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6903 - accuracy: 0.5859\n",
      "Epoch 21: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7299 - accuracy: 0.5591 - val_loss: 0.6764 - val_accuracy: 0.6170\n",
      "Epoch 22/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8026 - accuracy: 0.4922\n",
      "Epoch 22: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.7684 - accuracy: 0.5672 - val_loss: 0.6764 - val_accuracy: 0.6170\n",
      "Epoch 23/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6584 - accuracy: 0.6328\n",
      "Epoch 23: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6807 - accuracy: 0.6022 - val_loss: 0.6763 - val_accuracy: 0.6170\n",
      "Epoch 24/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8463 - accuracy: 0.4844\n",
      "Epoch 24: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7293 - accuracy: 0.5887 - val_loss: 0.6762 - val_accuracy: 0.6170\n",
      "Epoch 25/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7268 - accuracy: 0.6172\n",
      "Epoch 25: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7227 - accuracy: 0.5968 - val_loss: 0.6760 - val_accuracy: 0.6170\n",
      "Epoch 26/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7977 - accuracy: 0.5312\n",
      "Epoch 26: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7313 - accuracy: 0.5860 - val_loss: 0.6758 - val_accuracy: 0.6170\n",
      "Epoch 27/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7809 - accuracy: 0.4922\n",
      "Epoch 27: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7747 - accuracy: 0.5511 - val_loss: 0.6756 - val_accuracy: 0.6170\n",
      "Epoch 28/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7569 - accuracy: 0.5234\n",
      "Epoch 28: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.7233 - accuracy: 0.5672 - val_loss: 0.6755 - val_accuracy: 0.6170\n",
      "Epoch 29/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6178 - accuracy: 0.7188\n",
      "Epoch 29: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6798 - accuracy: 0.6237 - val_loss: 0.6753 - val_accuracy: 0.6170\n",
      "Epoch 30/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6259 - accuracy: 0.6562\n",
      "Epoch 30: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6816 - accuracy: 0.6263 - val_loss: 0.6752 - val_accuracy: 0.6170\n",
      "Epoch 31/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7319 - accuracy: 0.5156\n",
      "Epoch 31: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7038 - accuracy: 0.5645 - val_loss: 0.6750 - val_accuracy: 0.6064\n",
      "Epoch 32/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8041 - accuracy: 0.5547\n",
      "Epoch 32: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7275 - accuracy: 0.5753 - val_loss: 0.6749 - val_accuracy: 0.5957\n",
      "Epoch 33/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6264 - accuracy: 0.6406\n",
      "Epoch 33: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6668 - accuracy: 0.6183 - val_loss: 0.6746 - val_accuracy: 0.5957\n",
      "Epoch 34/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6773 - accuracy: 0.6172\n",
      "Epoch 34: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7096 - accuracy: 0.5995 - val_loss: 0.6744 - val_accuracy: 0.6064\n",
      "Epoch 35/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6753 - accuracy: 0.5547\n",
      "Epoch 35: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7003 - accuracy: 0.5591 - val_loss: 0.6741 - val_accuracy: 0.6170\n",
      "Epoch 36/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6590 - accuracy: 0.6094\n",
      "Epoch 36: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7034 - accuracy: 0.5914 - val_loss: 0.6738 - val_accuracy: 0.6170\n",
      "Epoch 37/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7016 - accuracy: 0.5859\n",
      "Epoch 37: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7113 - accuracy: 0.5806 - val_loss: 0.6736 - val_accuracy: 0.6170\n",
      "Epoch 38/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8355 - accuracy: 0.6016\n",
      "Epoch 38: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7345 - accuracy: 0.6048 - val_loss: 0.6735 - val_accuracy: 0.6277\n",
      "Epoch 39/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6992 - accuracy: 0.5938\n",
      "Epoch 39: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6894 - accuracy: 0.5914 - val_loss: 0.6733 - val_accuracy: 0.6277\n",
      "Epoch 40/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7154 - accuracy: 0.5938\n",
      "Epoch 40: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6974 - accuracy: 0.5833 - val_loss: 0.6733 - val_accuracy: 0.6277\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.5672\n",
      "Epoch 41: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.7041 - accuracy: 0.5672 - val_loss: 0.6732 - val_accuracy: 0.6277\n",
      "Epoch 42/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6820 - accuracy: 0.6016\n",
      "Epoch 42: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6801 - accuracy: 0.5860 - val_loss: 0.6730 - val_accuracy: 0.6170\n",
      "Epoch 43/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7505 - accuracy: 0.5391\n",
      "Epoch 43: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7011 - accuracy: 0.5591 - val_loss: 0.6729 - val_accuracy: 0.6170\n",
      "Epoch 44/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5932 - accuracy: 0.6641\n",
      "Epoch 44: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6764 - accuracy: 0.5833 - val_loss: 0.6727 - val_accuracy: 0.6170\n",
      "Epoch 45/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6649 - accuracy: 0.5703\n",
      "Epoch 45: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6469 - accuracy: 0.5941 - val_loss: 0.6726 - val_accuracy: 0.6170\n",
      "Epoch 46/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7229 - accuracy: 0.5781\n",
      "Epoch 46: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6836 - accuracy: 0.6210 - val_loss: 0.6724 - val_accuracy: 0.6170\n",
      "Epoch 47/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7143 - accuracy: 0.5547\n",
      "Epoch 47: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.7041 - accuracy: 0.5833 - val_loss: 0.6723 - val_accuracy: 0.6170\n",
      "Epoch 48/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6596 - accuracy: 0.6328\n",
      "Epoch 48: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.6632 - accuracy: 0.6129 - val_loss: 0.6721 - val_accuracy: 0.6170\n",
      "Epoch 49/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7158 - accuracy: 0.5703\n",
      "Epoch 49: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6742 - accuracy: 0.6022 - val_loss: 0.6719 - val_accuracy: 0.6170\n",
      "Epoch 50/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7103 - accuracy: 0.5703\n",
      "Epoch 50: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7008 - accuracy: 0.5672 - val_loss: 0.6716 - val_accuracy: 0.6170\n",
      "Epoch 51/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6440 - accuracy: 0.6250\n",
      "Epoch 51: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6737 - accuracy: 0.6156 - val_loss: 0.6715 - val_accuracy: 0.6170\n",
      "Epoch 52/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6087 - accuracy: 0.6562\n",
      "Epoch 52: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6726 - accuracy: 0.5968 - val_loss: 0.6713 - val_accuracy: 0.6170\n",
      "Epoch 53/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6638 - accuracy: 0.6172\n",
      "Epoch 53: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6556 - accuracy: 0.6022 - val_loss: 0.6712 - val_accuracy: 0.6170\n",
      "Epoch 54/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6510 - accuracy: 0.6172\n",
      "Epoch 54: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6896 - accuracy: 0.5968 - val_loss: 0.6709 - val_accuracy: 0.6064\n",
      "Epoch 55/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6715 - accuracy: 0.5859\n",
      "Epoch 55: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6803 - accuracy: 0.5860 - val_loss: 0.6708 - val_accuracy: 0.6064\n",
      "Epoch 56/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6655 - accuracy: 0.6406\n",
      "Epoch 56: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6751 - accuracy: 0.6048 - val_loss: 0.6705 - val_accuracy: 0.6064\n",
      "Epoch 57/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6757 - accuracy: 0.5625\n",
      "Epoch 57: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - accuracy: 0.5995 - val_loss: 0.6703 - val_accuracy: 0.6170\n",
      "Epoch 58/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6410 - accuracy: 0.6328\n",
      "Epoch 58: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6379 - accuracy: 0.6371 - val_loss: 0.6700 - val_accuracy: 0.6170\n",
      "Epoch 59/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6432 - accuracy: 0.6484\n",
      "Epoch 59: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6506 - accuracy: 0.6371 - val_loss: 0.6697 - val_accuracy: 0.6170\n",
      "Epoch 60/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7003 - accuracy: 0.6016\n",
      "Epoch 60: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6911 - accuracy: 0.5968 - val_loss: 0.6695 - val_accuracy: 0.6170\n",
      "Epoch 61/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6696 - accuracy: 0.5938\n",
      "Epoch 61: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6850 - accuracy: 0.5699 - val_loss: 0.6694 - val_accuracy: 0.6170\n",
      "Epoch 62/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6491 - accuracy: 0.5859\n",
      "Epoch 62: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.6775 - accuracy: 0.6022 - val_loss: 0.6692 - val_accuracy: 0.6170\n",
      "Epoch 63/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6481 - accuracy: 0.6172\n",
      "Epoch 63: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.6705 - accuracy: 0.6129 - val_loss: 0.6691 - val_accuracy: 0.6170\n",
      "Epoch 64/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6355 - accuracy: 0.5938\n",
      "Epoch 64: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.6648 - accuracy: 0.5968 - val_loss: 0.6689 - val_accuracy: 0.6170\n",
      "Epoch 65/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6672 - accuracy: 0.6016\n",
      "Epoch 65: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6858 - accuracy: 0.5941 - val_loss: 0.6686 - val_accuracy: 0.6170\n",
      "Epoch 66/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6162 - accuracy: 0.6094\n",
      "Epoch 66: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6451 - accuracy: 0.6156 - val_loss: 0.6683 - val_accuracy: 0.6170\n",
      "Epoch 67/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6674 - accuracy: 0.6250\n",
      "Epoch 67: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6742 - accuracy: 0.6129 - val_loss: 0.6680 - val_accuracy: 0.6170\n",
      "Epoch 68/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6674 - accuracy: 0.5938\n",
      "Epoch 68: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.6835 - accuracy: 0.6075 - val_loss: 0.6677 - val_accuracy: 0.6170\n",
      "Epoch 69/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6729 - accuracy: 0.6094\n",
      "Epoch 69: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.6428 - accuracy: 0.6210 - val_loss: 0.6678 - val_accuracy: 0.6170\n",
      "Epoch 70/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6352 - accuracy: 0.5938\n",
      "Epoch 70: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6498 - accuracy: 0.6129 - val_loss: 0.6676 - val_accuracy: 0.6170\n",
      "Epoch 71/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6484 - accuracy: 0.6641\n",
      "Epoch 71: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6815 - accuracy: 0.5968 - val_loss: 0.6674 - val_accuracy: 0.6170\n",
      "Epoch 72/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6695 - accuracy: 0.5938\n",
      "Epoch 72: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.6753 - accuracy: 0.6022 - val_loss: 0.6672 - val_accuracy: 0.6170\n",
      "Epoch 73/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7238 - accuracy: 0.5938\n",
      "Epoch 73: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6791 - accuracy: 0.6048 - val_loss: 0.6671 - val_accuracy: 0.6170\n",
      "Epoch 74/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7033 - accuracy: 0.6250\n",
      "Epoch 74: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6934 - accuracy: 0.5941 - val_loss: 0.6669 - val_accuracy: 0.6170\n",
      "Epoch 75/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6782 - accuracy: 0.5703\n",
      "Epoch 75: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6721 - accuracy: 0.6048 - val_loss: 0.6666 - val_accuracy: 0.6170\n",
      "Epoch 76/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6703 - accuracy: 0.6250\n",
      "Epoch 76: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6796 - accuracy: 0.5968 - val_loss: 0.6662 - val_accuracy: 0.6170\n",
      "Epoch 77/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6697 - accuracy: 0.6094\n",
      "Epoch 77: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6486 - accuracy: 0.6102 - val_loss: 0.6659 - val_accuracy: 0.6170\n",
      "Epoch 78/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6171 - accuracy: 0.6562\n",
      "Epoch 78: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.6700 - accuracy: 0.5806 - val_loss: 0.6657 - val_accuracy: 0.6277\n",
      "Epoch 79/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7028 - accuracy: 0.5547\n",
      "Epoch 79: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6651 - accuracy: 0.5887 - val_loss: 0.6655 - val_accuracy: 0.6277\n",
      "Epoch 80/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6482 - accuracy: 0.6484\n",
      "Epoch 80: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6448 - accuracy: 0.6156 - val_loss: 0.6652 - val_accuracy: 0.6277\n",
      "Epoch 81/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6338 - accuracy: 0.6016\n",
      "Epoch 81: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6611 - accuracy: 0.6075 - val_loss: 0.6648 - val_accuracy: 0.6277\n",
      "Epoch 82/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6441 - accuracy: 0.6406\n",
      "Epoch 82: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6432 - accuracy: 0.6290 - val_loss: 0.6645 - val_accuracy: 0.6277\n",
      "Epoch 83/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6832 - accuracy: 0.5312\n",
      "Epoch 83: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6571 - accuracy: 0.5941 - val_loss: 0.6641 - val_accuracy: 0.6277\n",
      "Epoch 84/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6709 - accuracy: 0.5781\n",
      "Epoch 84: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.6512 - accuracy: 0.6210 - val_loss: 0.6637 - val_accuracy: 0.6277\n",
      "Epoch 85/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6693 - accuracy: 0.5938\n",
      "Epoch 85: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6682 - accuracy: 0.6210 - val_loss: 0.6634 - val_accuracy: 0.6277\n",
      "Epoch 86/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5931 - accuracy: 0.6953\n",
      "Epoch 86: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6498 - accuracy: 0.6075 - val_loss: 0.6632 - val_accuracy: 0.6277\n",
      "Epoch 87/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6238 - accuracy: 0.6562\n",
      "Epoch 87: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6414 - accuracy: 0.6371 - val_loss: 0.6629 - val_accuracy: 0.6277\n",
      "Epoch 88/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6620 - accuracy: 0.6797\n",
      "Epoch 88: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6570 - accuracy: 0.6344 - val_loss: 0.6627 - val_accuracy: 0.6277\n",
      "Epoch 89/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6950 - accuracy: 0.5625\n",
      "Epoch 89: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6789 - accuracy: 0.5833 - val_loss: 0.6626 - val_accuracy: 0.6277\n",
      "Epoch 90/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6500 - accuracy: 0.5859\n",
      "Epoch 90: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6559 - accuracy: 0.6129 - val_loss: 0.6624 - val_accuracy: 0.6277\n",
      "Epoch 91/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6058 - accuracy: 0.6719\n",
      "Epoch 91: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6465 - accuracy: 0.6290 - val_loss: 0.6623 - val_accuracy: 0.6277\n",
      "Epoch 92/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7002 - accuracy: 0.5625\n",
      "Epoch 92: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6721 - accuracy: 0.5941 - val_loss: 0.6621 - val_accuracy: 0.6277\n",
      "Epoch 93/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6219 - accuracy: 0.6719\n",
      "Epoch 93: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6689 - accuracy: 0.5941 - val_loss: 0.6618 - val_accuracy: 0.6277\n",
      "Epoch 94/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6998 - accuracy: 0.5469\n",
      "Epoch 94: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6559 - accuracy: 0.6290 - val_loss: 0.6615 - val_accuracy: 0.6277\n",
      "Epoch 95/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6005 - accuracy: 0.6875\n",
      "Epoch 95: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6311 - accuracy: 0.6290 - val_loss: 0.6613 - val_accuracy: 0.6277\n",
      "Epoch 96/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6406 - accuracy: 0.5547\n",
      "Epoch 96: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6688 - accuracy: 0.6022 - val_loss: 0.6610 - val_accuracy: 0.6277\n",
      "Epoch 97/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6320 - accuracy: 0.6328\n",
      "Epoch 97: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6398 - accuracy: 0.6344 - val_loss: 0.6609 - val_accuracy: 0.6277\n",
      "Epoch 98/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6569 - accuracy: 0.6172\n",
      "Epoch 98: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.6680 - accuracy: 0.6156 - val_loss: 0.6606 - val_accuracy: 0.6277\n",
      "Epoch 99/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6406\n",
      "Epoch 99: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6322 - accuracy: 0.6344 - val_loss: 0.6603 - val_accuracy: 0.6277\n",
      "Epoch 100/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6892 - accuracy: 0.6016\n",
      "Epoch 100: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6531 - accuracy: 0.6344 - val_loss: 0.6601 - val_accuracy: 0.6277\n",
      "Epoch 101/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6489 - accuracy: 0.6328\n",
      "Epoch 101: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6464 - accuracy: 0.6317 - val_loss: 0.6598 - val_accuracy: 0.6277\n",
      "Epoch 102/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5882 - accuracy: 0.7031\n",
      "Epoch 102: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6242 - accuracy: 0.6452 - val_loss: 0.6594 - val_accuracy: 0.6277\n",
      "Epoch 103/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6431 - accuracy: 0.6406\n",
      "Epoch 103: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6397 - accuracy: 0.6290 - val_loss: 0.6591 - val_accuracy: 0.6277\n",
      "Epoch 104/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6233 - accuracy: 0.6250\n",
      "Epoch 104: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6544 - accuracy: 0.5995 - val_loss: 0.6588 - val_accuracy: 0.6277\n",
      "Epoch 105/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6165 - accuracy: 0.6562\n",
      "Epoch 105: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6370 - accuracy: 0.6559 - val_loss: 0.6586 - val_accuracy: 0.6277\n",
      "Epoch 106/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6535 - accuracy: 0.6406\n",
      "Epoch 106: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.6498 - accuracy: 0.6344 - val_loss: 0.6583 - val_accuracy: 0.6277\n",
      "Epoch 107/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6176 - accuracy: 0.6953\n",
      "Epoch 107: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.6411 - accuracy: 0.6371 - val_loss: 0.6580 - val_accuracy: 0.6277\n",
      "Epoch 108/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6517 - accuracy: 0.6172\n",
      "Epoch 108: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6489 - accuracy: 0.6371 - val_loss: 0.6578 - val_accuracy: 0.6277\n",
      "Epoch 109/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5930 - accuracy: 0.6797\n",
      "Epoch 109: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6455 - accuracy: 0.6344 - val_loss: 0.6574 - val_accuracy: 0.6277\n",
      "Epoch 110/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6586 - accuracy: 0.6250\n",
      "Epoch 110: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6574 - accuracy: 0.6290 - val_loss: 0.6571 - val_accuracy: 0.6277\n",
      "Epoch 111/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6502 - accuracy: 0.6094\n",
      "Epoch 111: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6471 - accuracy: 0.6478 - val_loss: 0.6570 - val_accuracy: 0.6277\n",
      "Epoch 112/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6293 - accuracy: 0.6680\n",
      "Epoch 112: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.6358 - accuracy: 0.6640 - val_loss: 0.6566 - val_accuracy: 0.6277\n",
      "Epoch 113/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6094\n",
      "Epoch 113: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6391 - accuracy: 0.6210 - val_loss: 0.6562 - val_accuracy: 0.6277\n",
      "Epoch 114/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6940 - accuracy: 0.5391\n",
      "Epoch 114: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.6722 - accuracy: 0.6075 - val_loss: 0.6558 - val_accuracy: 0.6277\n",
      "Epoch 115/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6726 - accuracy: 0.6172\n",
      "Epoch 115: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6490 - accuracy: 0.6048 - val_loss: 0.6555 - val_accuracy: 0.6277\n",
      "Epoch 116/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6535 - accuracy: 0.6016\n",
      "Epoch 116: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6442 - accuracy: 0.6210 - val_loss: 0.6550 - val_accuracy: 0.6277\n",
      "Epoch 117/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6653 - accuracy: 0.5703\n",
      "Epoch 117: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6460 - accuracy: 0.6075 - val_loss: 0.6544 - val_accuracy: 0.6277\n",
      "Epoch 118/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6388 - accuracy: 0.6016\n",
      "Epoch 118: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6478 - accuracy: 0.6317 - val_loss: 0.6538 - val_accuracy: 0.6277\n",
      "Epoch 119/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6436 - accuracy: 0.6172\n",
      "Epoch 119: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6429 - accuracy: 0.6290 - val_loss: 0.6535 - val_accuracy: 0.6277\n",
      "Epoch 120/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6095 - accuracy: 0.6797\n",
      "Epoch 120: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6404 - accuracy: 0.6452 - val_loss: 0.6533 - val_accuracy: 0.6383\n",
      "Epoch 121/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6382 - accuracy: 0.6719\n",
      "Epoch 121: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6278 - accuracy: 0.6452 - val_loss: 0.6530 - val_accuracy: 0.6277\n",
      "Epoch 122/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6254 - accuracy: 0.6172\n",
      "Epoch 122: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6322 - accuracy: 0.6290 - val_loss: 0.6527 - val_accuracy: 0.6383\n",
      "Epoch 123/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6287 - accuracy: 0.6328\n",
      "Epoch 123: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6177 - accuracy: 0.6505 - val_loss: 0.6523 - val_accuracy: 0.6383\n",
      "Epoch 124/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6088 - accuracy: 0.6562\n",
      "Epoch 124: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6294 - accuracy: 0.6317 - val_loss: 0.6518 - val_accuracy: 0.6383\n",
      "Epoch 125/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6136 - accuracy: 0.7109\n",
      "Epoch 125: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6353 - accuracy: 0.6586 - val_loss: 0.6513 - val_accuracy: 0.6277\n",
      "Epoch 126/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6763 - accuracy: 0.6250\n",
      "Epoch 126: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6601 - accuracy: 0.6371 - val_loss: 0.6508 - val_accuracy: 0.6277\n",
      "Epoch 127/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6589 - accuracy: 0.5859\n",
      "Epoch 127: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6422 - accuracy: 0.6263 - val_loss: 0.6504 - val_accuracy: 0.6383\n",
      "Epoch 128/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6150 - accuracy: 0.6562\n",
      "Epoch 128: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6415 - accuracy: 0.6263 - val_loss: 0.6500 - val_accuracy: 0.6383\n",
      "Epoch 129/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6640 - accuracy: 0.6016\n",
      "Epoch 129: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6558 - accuracy: 0.6263 - val_loss: 0.6496 - val_accuracy: 0.6383\n",
      "Epoch 130/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6461 - accuracy: 0.6016\n",
      "Epoch 130: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6366 - accuracy: 0.6183 - val_loss: 0.6494 - val_accuracy: 0.6383\n",
      "Epoch 131/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6227 - accuracy: 0.6172\n",
      "Epoch 131: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6385 - accuracy: 0.6290 - val_loss: 0.6491 - val_accuracy: 0.6277\n",
      "Epoch 132/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6980 - accuracy: 0.5469\n",
      "Epoch 132: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6317 - accuracy: 0.6505 - val_loss: 0.6490 - val_accuracy: 0.6277\n",
      "Epoch 133/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6820 - accuracy: 0.5391\n",
      "Epoch 133: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6600 - accuracy: 0.5887 - val_loss: 0.6490 - val_accuracy: 0.6277\n",
      "Epoch 134/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6290 - accuracy: 0.7031\n",
      "Epoch 134: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6271 - accuracy: 0.6720 - val_loss: 0.6487 - val_accuracy: 0.6277\n",
      "Epoch 135/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6555 - accuracy: 0.6406\n",
      "Epoch 135: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6332 - accuracy: 0.6586 - val_loss: 0.6484 - val_accuracy: 0.6277\n",
      "Epoch 136/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6469 - accuracy: 0.6094\n",
      "Epoch 136: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6540 - accuracy: 0.6156 - val_loss: 0.6480 - val_accuracy: 0.6489\n",
      "Epoch 137/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6279 - accuracy: 0.6172\n",
      "Epoch 137: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6391 - accuracy: 0.6183 - val_loss: 0.6476 - val_accuracy: 0.6489\n",
      "Epoch 138/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6387 - accuracy: 0.6094\n",
      "Epoch 138: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6259 - accuracy: 0.6532 - val_loss: 0.6471 - val_accuracy: 0.6489\n",
      "Epoch 139/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6013 - accuracy: 0.6562\n",
      "Epoch 139: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6408 - accuracy: 0.6317 - val_loss: 0.6464 - val_accuracy: 0.6383\n",
      "Epoch 140/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5848 - accuracy: 0.6797\n",
      "Epoch 140: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6377 - accuracy: 0.6210 - val_loss: 0.6458 - val_accuracy: 0.6383\n",
      "Epoch 141/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6507 - accuracy: 0.5703\n",
      "Epoch 141: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6411 - accuracy: 0.6102 - val_loss: 0.6455 - val_accuracy: 0.6383\n",
      "Epoch 142/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6338 - accuracy: 0.6094\n",
      "Epoch 142: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6294 - accuracy: 0.6559 - val_loss: 0.6455 - val_accuracy: 0.6489\n",
      "Epoch 143/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6092 - accuracy: 0.6719\n",
      "Epoch 143: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6262 - accuracy: 0.6425 - val_loss: 0.6453 - val_accuracy: 0.6489\n",
      "Epoch 144/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6088 - accuracy: 0.6484\n",
      "Epoch 144: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6412 - accuracy: 0.6210 - val_loss: 0.6448 - val_accuracy: 0.6489\n",
      "Epoch 145/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6319 - accuracy: 0.6484\n",
      "Epoch 145: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6374 - accuracy: 0.6398 - val_loss: 0.6443 - val_accuracy: 0.6489\n",
      "Epoch 146/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6223 - accuracy: 0.6953\n",
      "Epoch 146: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6203 - accuracy: 0.6667 - val_loss: 0.6437 - val_accuracy: 0.6489\n",
      "Epoch 147/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6039 - accuracy: 0.6406\n",
      "Epoch 147: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6209 - accuracy: 0.6398 - val_loss: 0.6433 - val_accuracy: 0.6489\n",
      "Epoch 148/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6289 - accuracy: 0.6484\n",
      "Epoch 148: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6198 - accuracy: 0.6398 - val_loss: 0.6427 - val_accuracy: 0.6383\n",
      "Epoch 149/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6275 - accuracy: 0.6406\n",
      "Epoch 149: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6300 - accuracy: 0.6505 - val_loss: 0.6422 - val_accuracy: 0.6489\n",
      "Epoch 150/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5981 - accuracy: 0.7031\n",
      "Epoch 150: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6166 - accuracy: 0.6505 - val_loss: 0.6417 - val_accuracy: 0.6383\n",
      "Epoch 151/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6259 - accuracy: 0.6484\n",
      "Epoch 151: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6341 - accuracy: 0.6532 - val_loss: 0.6412 - val_accuracy: 0.6383\n",
      "Epoch 152/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6168 - accuracy: 0.6562\n",
      "Epoch 152: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.6352 - accuracy: 0.6478 - val_loss: 0.6410 - val_accuracy: 0.6383\n",
      "Epoch 153/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6066 - accuracy: 0.6641\n",
      "Epoch 153: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6235 - accuracy: 0.6452 - val_loss: 0.6408 - val_accuracy: 0.6383\n",
      "Epoch 154/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6146 - accuracy: 0.6641\n",
      "Epoch 154: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6328 - accuracy: 0.6263 - val_loss: 0.6407 - val_accuracy: 0.6383\n",
      "Epoch 155/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6614 - accuracy: 0.6719\n",
      "Epoch 155: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6621 - accuracy: 0.6075 - val_loss: 0.6406 - val_accuracy: 0.6489\n",
      "Epoch 156/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6565 - accuracy: 0.6250\n",
      "Epoch 156: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6467 - accuracy: 0.6183 - val_loss: 0.6406 - val_accuracy: 0.6596\n",
      "Epoch 157/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6355 - accuracy: 0.6562\n",
      "Epoch 157: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6306 - accuracy: 0.6344 - val_loss: 0.6402 - val_accuracy: 0.6596\n",
      "Epoch 158/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6843 - accuracy: 0.6250\n",
      "Epoch 158: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6437 - accuracy: 0.6290 - val_loss: 0.6397 - val_accuracy: 0.6596\n",
      "Epoch 159/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6566 - accuracy: 0.6328\n",
      "Epoch 159: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6367 - accuracy: 0.6505 - val_loss: 0.6393 - val_accuracy: 0.6596\n",
      "Epoch 160/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6477 - accuracy: 0.5781\n",
      "Epoch 160: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6245 - accuracy: 0.6425 - val_loss: 0.6387 - val_accuracy: 0.6596\n",
      "Epoch 161/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6418 - accuracy: 0.6562\n",
      "Epoch 161: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6278 - accuracy: 0.6452 - val_loss: 0.6384 - val_accuracy: 0.6489\n",
      "Epoch 162/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6220 - accuracy: 0.6641\n",
      "Epoch 162: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6304 - accuracy: 0.6452 - val_loss: 0.6378 - val_accuracy: 0.6596\n",
      "Epoch 163/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6353 - accuracy: 0.6172\n",
      "Epoch 163: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6295 - accuracy: 0.6183 - val_loss: 0.6373 - val_accuracy: 0.6596\n",
      "Epoch 164/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6696 - accuracy: 0.6172\n",
      "Epoch 164: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6429 - accuracy: 0.6183 - val_loss: 0.6369 - val_accuracy: 0.6489\n",
      "Epoch 165/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6170 - accuracy: 0.6406\n",
      "Epoch 165: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6296 - accuracy: 0.6452 - val_loss: 0.6369 - val_accuracy: 0.6596\n",
      "Epoch 166/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6464 - accuracy: 0.5938\n",
      "Epoch 166: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6365 - accuracy: 0.6075 - val_loss: 0.6369 - val_accuracy: 0.6596\n",
      "Epoch 167/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6880 - accuracy: 0.5547\n",
      "Epoch 167: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6454 - accuracy: 0.6210 - val_loss: 0.6373 - val_accuracy: 0.6489\n",
      "Epoch 168/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6219 - accuracy: 0.6094\n",
      "Epoch 168: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6233 - accuracy: 0.6344 - val_loss: 0.6371 - val_accuracy: 0.6489\n",
      "Epoch 169/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6456 - accuracy: 0.6562\n",
      "Epoch 169: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6185 - accuracy: 0.6613 - val_loss: 0.6366 - val_accuracy: 0.6489\n",
      "Epoch 170/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6111 - accuracy: 0.6641\n",
      "Epoch 170: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6184 - accuracy: 0.6505 - val_loss: 0.6363 - val_accuracy: 0.6489\n",
      "Epoch 171/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6362 - accuracy: 0.6094\n",
      "Epoch 171: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6238 - accuracy: 0.6210 - val_loss: 0.6361 - val_accuracy: 0.6489\n",
      "Epoch 172/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6113 - accuracy: 0.6562\n",
      "Epoch 172: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6338 - accuracy: 0.6344 - val_loss: 0.6357 - val_accuracy: 0.6489\n",
      "Epoch 173/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6292 - accuracy: 0.6406\n",
      "Epoch 173: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6193 - accuracy: 0.6532 - val_loss: 0.6354 - val_accuracy: 0.6489\n",
      "Epoch 174/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6896 - accuracy: 0.5547\n",
      "Epoch 174: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6377 - accuracy: 0.6210 - val_loss: 0.6351 - val_accuracy: 0.6489\n",
      "Epoch 175/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6403 - accuracy: 0.6328\n",
      "Epoch 175: val_accuracy did not improve from 0.65957\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6298 - accuracy: 0.6559 - val_loss: 0.6348 - val_accuracy: 0.6596\n",
      "Epoch 176/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6211 - accuracy: 0.6875\n",
      "Epoch 176: val_accuracy improved from 0.65957 to 0.68085, saving model to .\\SIN492-0176.hdf5\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.6280 - accuracy: 0.6640 - val_loss: 0.6345 - val_accuracy: 0.6809\n",
      "Epoch 177/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6138 - accuracy: 0.6484\n",
      "Epoch 177: val_accuracy did not improve from 0.68085\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6300 - accuracy: 0.6156 - val_loss: 0.6337 - val_accuracy: 0.6809\n",
      "Epoch 178/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6334 - accuracy: 0.6484\n",
      "Epoch 178: val_accuracy did not improve from 0.68085\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6196 - accuracy: 0.6505 - val_loss: 0.6331 - val_accuracy: 0.6809\n",
      "Epoch 179/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6227 - accuracy: 0.6484\n",
      "Epoch 179: val_accuracy improved from 0.68085 to 0.69149, saving model to .\\SIN492-0179.hdf5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6196 - accuracy: 0.6559 - val_loss: 0.6321 - val_accuracy: 0.6915\n",
      "Epoch 180/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6430 - accuracy: 0.5859\n",
      "Epoch 180: val_accuracy did not improve from 0.69149\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6313 - accuracy: 0.6505 - val_loss: 0.6314 - val_accuracy: 0.6915\n",
      "Epoch 181/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6255 - accuracy: 0.6406\n",
      "Epoch 181: val_accuracy improved from 0.69149 to 0.70213, saving model to .\\SIN492-0181.hdf5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6266 - accuracy: 0.6210 - val_loss: 0.6309 - val_accuracy: 0.7021\n",
      "Epoch 182/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6262 - accuracy: 0.6328\n",
      "Epoch 182: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6296 - accuracy: 0.6317 - val_loss: 0.6307 - val_accuracy: 0.7021\n",
      "Epoch 183/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6317 - accuracy: 0.6562\n",
      "Epoch 183: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6378 - accuracy: 0.6398 - val_loss: 0.6305 - val_accuracy: 0.6915\n",
      "Epoch 184/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6812 - accuracy: 0.6016\n",
      "Epoch 184: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6318 - accuracy: 0.6532 - val_loss: 0.6303 - val_accuracy: 0.6915\n",
      "Epoch 185/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6057 - accuracy: 0.6641\n",
      "Epoch 185: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6157 - accuracy: 0.6452 - val_loss: 0.6299 - val_accuracy: 0.6915\n",
      "Epoch 186/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6111 - accuracy: 0.6094\n",
      "Epoch 186: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.6091 - accuracy: 0.6505 - val_loss: 0.6296 - val_accuracy: 0.6915\n",
      "Epoch 187/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6488 - accuracy: 0.6406\n",
      "Epoch 187: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6304 - accuracy: 0.6505 - val_loss: 0.6296 - val_accuracy: 0.6915\n",
      "Epoch 188/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6464 - accuracy: 0.6016\n",
      "Epoch 188: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.6267 - accuracy: 0.6156 - val_loss: 0.6295 - val_accuracy: 0.7021\n",
      "Epoch 189/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6078 - accuracy: 0.7109\n",
      "Epoch 189: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6228 - accuracy: 0.6640 - val_loss: 0.6287 - val_accuracy: 0.7021\n",
      "Epoch 190/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5814 - accuracy: 0.7188\n",
      "Epoch 190: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6202 - accuracy: 0.6371 - val_loss: 0.6284 - val_accuracy: 0.6915\n",
      "Epoch 191/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6571 - accuracy: 0.6328\n",
      "Epoch 191: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6257 - accuracy: 0.6452 - val_loss: 0.6286 - val_accuracy: 0.6915\n",
      "Epoch 192/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6806 - accuracy: 0.5859\n",
      "Epoch 192: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6200 - accuracy: 0.6559 - val_loss: 0.6287 - val_accuracy: 0.6915\n",
      "Epoch 193/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6536 - accuracy: 0.5781\n",
      "Epoch 193: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6276 - accuracy: 0.6425 - val_loss: 0.6286 - val_accuracy: 0.6915\n",
      "Epoch 194/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6315 - accuracy: 0.6328\n",
      "Epoch 194: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6152 - accuracy: 0.6478 - val_loss: 0.6282 - val_accuracy: 0.6915\n",
      "Epoch 195/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6372 - accuracy: 0.6328\n",
      "Epoch 195: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6383 - accuracy: 0.6344 - val_loss: 0.6279 - val_accuracy: 0.6915\n",
      "Epoch 196/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6193 - accuracy: 0.6641\n",
      "Epoch 196: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6311 - accuracy: 0.6344 - val_loss: 0.6277 - val_accuracy: 0.6915\n",
      "Epoch 197/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5811 - accuracy: 0.7109\n",
      "Epoch 197: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6201 - accuracy: 0.6559 - val_loss: 0.6275 - val_accuracy: 0.7021\n",
      "Epoch 198/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6292 - accuracy: 0.5781\n",
      "Epoch 198: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6267 - accuracy: 0.6102 - val_loss: 0.6273 - val_accuracy: 0.7021\n",
      "Epoch 199/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6397 - accuracy: 0.6250\n",
      "Epoch 199: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6176 - accuracy: 0.6425 - val_loss: 0.6279 - val_accuracy: 0.7021\n",
      "Epoch 200/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6475 - accuracy: 0.6094\n",
      "Epoch 200: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6272 - accuracy: 0.6371 - val_loss: 0.6288 - val_accuracy: 0.7021\n",
      "Epoch 201/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6075 - accuracy: 0.6406\n",
      "Epoch 201: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6168 - accuracy: 0.6317 - val_loss: 0.6296 - val_accuracy: 0.7021\n",
      "Epoch 202/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6591 - accuracy: 0.5859\n",
      "Epoch 202: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.6450 - accuracy: 0.6237 - val_loss: 0.6304 - val_accuracy: 0.7021\n",
      "Epoch 203/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6235 - accuracy: 0.6641\n",
      "Epoch 203: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6469 - accuracy: 0.6344 - val_loss: 0.6302 - val_accuracy: 0.7021\n",
      "Epoch 204/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6318 - accuracy: 0.6797\n",
      "Epoch 204: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6565 - accuracy: 0.6183 - val_loss: 0.6293 - val_accuracy: 0.7021\n",
      "Epoch 205/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6045 - accuracy: 0.6641\n",
      "Epoch 205: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6280 - accuracy: 0.6344 - val_loss: 0.6284 - val_accuracy: 0.7021\n",
      "Epoch 206/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6244 - accuracy: 0.6641\n",
      "Epoch 206: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6207 - accuracy: 0.6720 - val_loss: 0.6276 - val_accuracy: 0.7021\n",
      "Epoch 207/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5958 - accuracy: 0.6562\n",
      "Epoch 207: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.6288 - accuracy: 0.6263 - val_loss: 0.6269 - val_accuracy: 0.7021\n",
      "Epoch 208/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6451 - accuracy: 0.5938\n",
      "Epoch 208: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.6229 - accuracy: 0.6452 - val_loss: 0.6262 - val_accuracy: 0.7021\n",
      "Epoch 209/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6754 - accuracy: 0.5625\n",
      "Epoch 209: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.6325 - accuracy: 0.6210 - val_loss: 0.6260 - val_accuracy: 0.7021\n",
      "Epoch 210/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6737 - accuracy: 0.5625\n",
      "Epoch 210: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6309 - accuracy: 0.6290 - val_loss: 0.6255 - val_accuracy: 0.6915\n",
      "Epoch 211/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6149 - accuracy: 0.6484\n",
      "Epoch 211: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6089 - accuracy: 0.6586 - val_loss: 0.6249 - val_accuracy: 0.6915\n",
      "Epoch 212/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5942 - accuracy: 0.7109\n",
      "Epoch 212: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6418 - accuracy: 0.6371 - val_loss: 0.6239 - val_accuracy: 0.6915\n",
      "Epoch 213/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6358 - accuracy: 0.6172\n",
      "Epoch 213: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6247 - accuracy: 0.6317 - val_loss: 0.6232 - val_accuracy: 0.6915\n",
      "Epoch 214/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6007 - accuracy: 0.6562\n",
      "Epoch 214: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6206 - accuracy: 0.6452 - val_loss: 0.6224 - val_accuracy: 0.6915\n",
      "Epoch 215/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6264 - accuracy: 0.6328\n",
      "Epoch 215: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6137 - accuracy: 0.6505 - val_loss: 0.6220 - val_accuracy: 0.6915\n",
      "Epoch 216/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6593 - accuracy: 0.5781\n",
      "Epoch 216: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6445 - accuracy: 0.5995 - val_loss: 0.6221 - val_accuracy: 0.6915\n",
      "Epoch 217/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6348 - accuracy: 0.6328\n",
      "Epoch 217: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6322 - accuracy: 0.6371 - val_loss: 0.6226 - val_accuracy: 0.6915\n",
      "Epoch 218/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6502 - accuracy: 0.6406\n",
      "Epoch 218: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6255 - accuracy: 0.6478 - val_loss: 0.6231 - val_accuracy: 0.6915\n",
      "Epoch 219/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6339 - accuracy: 0.6172\n",
      "Epoch 219: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6108 - accuracy: 0.6452 - val_loss: 0.6230 - val_accuracy: 0.6915\n",
      "Epoch 220/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6579 - accuracy: 0.6172\n",
      "Epoch 220: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6266 - accuracy: 0.6425 - val_loss: 0.6228 - val_accuracy: 0.6915\n",
      "Epoch 221/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6155 - accuracy: 0.6484\n",
      "Epoch 221: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.6205 - accuracy: 0.6478 - val_loss: 0.6221 - val_accuracy: 0.6915\n",
      "Epoch 222/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6455 - accuracy: 0.6328\n",
      "Epoch 222: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6293 - accuracy: 0.6398 - val_loss: 0.6212 - val_accuracy: 0.6915\n",
      "Epoch 223/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6321 - accuracy: 0.6172\n",
      "Epoch 223: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6305 - accuracy: 0.6398 - val_loss: 0.6205 - val_accuracy: 0.6915\n",
      "Epoch 224/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6146 - accuracy: 0.6484\n",
      "Epoch 224: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6290 - accuracy: 0.6452 - val_loss: 0.6203 - val_accuracy: 0.6809\n",
      "Epoch 225/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6022 - accuracy: 0.6797\n",
      "Epoch 225: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6191 - accuracy: 0.6452 - val_loss: 0.6200 - val_accuracy: 0.6809\n",
      "Epoch 226/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5932 - accuracy: 0.6406\n",
      "Epoch 226: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6235 - accuracy: 0.6505 - val_loss: 0.6200 - val_accuracy: 0.6915\n",
      "Epoch 227/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6108 - accuracy: 0.6406\n",
      "Epoch 227: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6099 - accuracy: 0.6398 - val_loss: 0.6198 - val_accuracy: 0.7021\n",
      "Epoch 228/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6040 - accuracy: 0.7031\n",
      "Epoch 228: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6188 - accuracy: 0.6559 - val_loss: 0.6190 - val_accuracy: 0.7021\n",
      "Epoch 229/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6289 - accuracy: 0.6484\n",
      "Epoch 229: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6237 - accuracy: 0.6452 - val_loss: 0.6185 - val_accuracy: 0.6809\n",
      "Epoch 230/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6210 - accuracy: 0.6562\n",
      "Epoch 230: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6130 - accuracy: 0.6505 - val_loss: 0.6182 - val_accuracy: 0.6809\n",
      "Epoch 231/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6748 - accuracy: 0.6094\n",
      "Epoch 231: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6450 - accuracy: 0.6290 - val_loss: 0.6182 - val_accuracy: 0.7021\n",
      "Epoch 232/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6238 - accuracy: 0.6641\n",
      "Epoch 232: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6245 - accuracy: 0.6559 - val_loss: 0.6181 - val_accuracy: 0.7021\n",
      "Epoch 233/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5980 - accuracy: 0.6953\n",
      "Epoch 233: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6249 - accuracy: 0.6505 - val_loss: 0.6177 - val_accuracy: 0.7021\n",
      "Epoch 234/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6490 - accuracy: 0.6094\n",
      "Epoch 234: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6356 - accuracy: 0.6183 - val_loss: 0.6176 - val_accuracy: 0.6915\n",
      "Epoch 235/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6089 - accuracy: 0.6484\n",
      "Epoch 235: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6204 - accuracy: 0.6237 - val_loss: 0.6183 - val_accuracy: 0.6915\n",
      "Epoch 236/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5973 - accuracy: 0.7031\n",
      "Epoch 236: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6260 - accuracy: 0.6505 - val_loss: 0.6182 - val_accuracy: 0.6915\n",
      "Epoch 237/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6302 - accuracy: 0.6250\n",
      "Epoch 237: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6136 - accuracy: 0.6505 - val_loss: 0.6175 - val_accuracy: 0.6809\n",
      "Epoch 238/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6638 - accuracy: 0.5938\n",
      "Epoch 238: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6325 - accuracy: 0.6505 - val_loss: 0.6174 - val_accuracy: 0.6809\n",
      "Epoch 239/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6094\n",
      "Epoch 239: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6131 - accuracy: 0.6532 - val_loss: 0.6173 - val_accuracy: 0.6809\n",
      "Epoch 240/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6449 - accuracy: 0.6094\n",
      "Epoch 240: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6179 - accuracy: 0.6478 - val_loss: 0.6173 - val_accuracy: 0.6809\n",
      "Epoch 241/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6409 - accuracy: 0.6172\n",
      "Epoch 241: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6217 - accuracy: 0.6478 - val_loss: 0.6171 - val_accuracy: 0.6915\n",
      "Epoch 242/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6143 - accuracy: 0.6328\n",
      "Epoch 242: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6119 - accuracy: 0.6452 - val_loss: 0.6174 - val_accuracy: 0.6915\n",
      "Epoch 243/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5783 - accuracy: 0.6875\n",
      "Epoch 243: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6168 - accuracy: 0.6478 - val_loss: 0.6170 - val_accuracy: 0.6915\n",
      "Epoch 244/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5843 - accuracy: 0.6719\n",
      "Epoch 244: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6118 - accuracy: 0.6586 - val_loss: 0.6158 - val_accuracy: 0.6915\n",
      "Epoch 245/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6067 - accuracy: 0.6250\n",
      "Epoch 245: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6124 - accuracy: 0.6613 - val_loss: 0.6146 - val_accuracy: 0.6915\n",
      "Epoch 246/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6312 - accuracy: 0.6172\n",
      "Epoch 246: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6123 - accuracy: 0.6747 - val_loss: 0.6141 - val_accuracy: 0.6915\n",
      "Epoch 247/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6383 - accuracy: 0.6641\n",
      "Epoch 247: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6336 - accuracy: 0.6505 - val_loss: 0.6140 - val_accuracy: 0.7021\n",
      "Epoch 248/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6252 - accuracy: 0.6406\n",
      "Epoch 248: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6187 - accuracy: 0.6532 - val_loss: 0.6141 - val_accuracy: 0.7021\n",
      "Epoch 249/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6163 - accuracy: 0.6797\n",
      "Epoch 249: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6180 - accuracy: 0.6694 - val_loss: 0.6140 - val_accuracy: 0.7021\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.6532\n",
      "Epoch 250: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.6316 - accuracy: 0.6532 - val_loss: 0.6143 - val_accuracy: 0.7021\n",
      "Epoch 251/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6019 - accuracy: 0.6719\n",
      "Epoch 251: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6153 - accuracy: 0.6371 - val_loss: 0.6142 - val_accuracy: 0.6915\n",
      "Epoch 252/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6458 - accuracy: 0.5859\n",
      "Epoch 252: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6194 - accuracy: 0.6505 - val_loss: 0.6139 - val_accuracy: 0.6915\n",
      "Epoch 253/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6058 - accuracy: 0.7109\n",
      "Epoch 253: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6180 - accuracy: 0.6559 - val_loss: 0.6139 - val_accuracy: 0.6915\n",
      "Epoch 254/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5889 - accuracy: 0.7109\n",
      "Epoch 254: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6385 - accuracy: 0.6371 - val_loss: 0.6144 - val_accuracy: 0.6915\n",
      "Epoch 255/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6375 - accuracy: 0.6328\n",
      "Epoch 255: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6214 - accuracy: 0.6425 - val_loss: 0.6149 - val_accuracy: 0.6915\n",
      "Epoch 256/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6272 - accuracy: 0.6328\n",
      "Epoch 256: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6207 - accuracy: 0.6290 - val_loss: 0.6151 - val_accuracy: 0.6915\n",
      "Epoch 257/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6400 - accuracy: 0.6250\n",
      "Epoch 257: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6137 - accuracy: 0.6586 - val_loss: 0.6152 - val_accuracy: 0.6915\n",
      "Epoch 258/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6056 - accuracy: 0.6797\n",
      "Epoch 258: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6077 - accuracy: 0.6613 - val_loss: 0.6151 - val_accuracy: 0.6915\n",
      "Epoch 259/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5690 - accuracy: 0.7344\n",
      "Epoch 259: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.6068 - accuracy: 0.6640 - val_loss: 0.6148 - val_accuracy: 0.6915\n",
      "Epoch 260/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6248 - accuracy: 0.6641\n",
      "Epoch 260: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6230 - accuracy: 0.6505 - val_loss: 0.6145 - val_accuracy: 0.6915\n",
      "Epoch 261/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6322 - accuracy: 0.6250\n",
      "Epoch 261: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.6148 - accuracy: 0.6478 - val_loss: 0.6146 - val_accuracy: 0.6915\n",
      "Epoch 262/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6489 - accuracy: 0.5938\n",
      "Epoch 262: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6342 - accuracy: 0.6210 - val_loss: 0.6146 - val_accuracy: 0.6809\n",
      "Epoch 263/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6172 - accuracy: 0.6172\n",
      "Epoch 263: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6128 - accuracy: 0.6344 - val_loss: 0.6143 - val_accuracy: 0.6809\n",
      "Epoch 264/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6717 - accuracy: 0.5547\n",
      "Epoch 264: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6288 - accuracy: 0.6263 - val_loss: 0.6142 - val_accuracy: 0.6809\n",
      "Epoch 265/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6161 - accuracy: 0.6484\n",
      "Epoch 265: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6122 - accuracy: 0.6640 - val_loss: 0.6141 - val_accuracy: 0.6809\n",
      "Epoch 266/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6442 - accuracy: 0.6406\n",
      "Epoch 266: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6242 - accuracy: 0.6371 - val_loss: 0.6141 - val_accuracy: 0.6915\n",
      "Epoch 267/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6497 - accuracy: 0.6172\n",
      "Epoch 267: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6218 - accuracy: 0.6478 - val_loss: 0.6155 - val_accuracy: 0.6702\n",
      "Epoch 268/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6033 - accuracy: 0.6484\n",
      "Epoch 268: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6158 - accuracy: 0.6425 - val_loss: 0.6165 - val_accuracy: 0.6702\n",
      "Epoch 269/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6164 - accuracy: 0.6562\n",
      "Epoch 269: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6105 - accuracy: 0.6613 - val_loss: 0.6174 - val_accuracy: 0.6809\n",
      "Epoch 270/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5859 - accuracy: 0.6875\n",
      "Epoch 270: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6105 - accuracy: 0.6667 - val_loss: 0.6173 - val_accuracy: 0.6809\n",
      "Epoch 271/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6269 - accuracy: 0.6172\n",
      "Epoch 271: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6147 - accuracy: 0.6559 - val_loss: 0.6167 - val_accuracy: 0.6809\n",
      "Epoch 272/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6099 - accuracy: 0.6328\n",
      "Epoch 272: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6173 - accuracy: 0.6129 - val_loss: 0.6150 - val_accuracy: 0.6702\n",
      "Epoch 273/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6666 - accuracy: 0.5781\n",
      "Epoch 273: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6233 - accuracy: 0.6425 - val_loss: 0.6138 - val_accuracy: 0.6809\n",
      "Epoch 274/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6326 - accuracy: 0.6406\n",
      "Epoch 274: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6131 - accuracy: 0.6613 - val_loss: 0.6131 - val_accuracy: 0.6915\n",
      "Epoch 275/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6085 - accuracy: 0.6641\n",
      "Epoch 275: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6230 - accuracy: 0.6532 - val_loss: 0.6129 - val_accuracy: 0.6915\n",
      "Epoch 276/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6602 - accuracy: 0.5859\n",
      "Epoch 276: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6309 - accuracy: 0.6452 - val_loss: 0.6132 - val_accuracy: 0.6915\n",
      "Epoch 277/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6144 - accuracy: 0.6484\n",
      "Epoch 277: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6207 - accuracy: 0.6532 - val_loss: 0.6126 - val_accuracy: 0.6915\n",
      "Epoch 278/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6019 - accuracy: 0.6797\n",
      "Epoch 278: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6185 - accuracy: 0.6425 - val_loss: 0.6122 - val_accuracy: 0.6809\n",
      "Epoch 279/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6068 - accuracy: 0.6406\n",
      "Epoch 279: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6271 - accuracy: 0.6586 - val_loss: 0.6115 - val_accuracy: 0.6809\n",
      "Epoch 280/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6667 - accuracy: 0.6094\n",
      "Epoch 280: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6207 - accuracy: 0.6532 - val_loss: 0.6118 - val_accuracy: 0.6702\n",
      "Epoch 281/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5809 - accuracy: 0.6953\n",
      "Epoch 281: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6079 - accuracy: 0.6640 - val_loss: 0.6119 - val_accuracy: 0.6809\n",
      "Epoch 282/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6057 - accuracy: 0.6562\n",
      "Epoch 282: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6229 - accuracy: 0.6371 - val_loss: 0.6122 - val_accuracy: 0.6915\n",
      "Epoch 283/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6128 - accuracy: 0.6641\n",
      "Epoch 283: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6161 - accuracy: 0.6425 - val_loss: 0.6123 - val_accuracy: 0.6915\n",
      "Epoch 284/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6151 - accuracy: 0.6562\n",
      "Epoch 284: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6058 - accuracy: 0.6586 - val_loss: 0.6109 - val_accuracy: 0.6915\n",
      "Epoch 285/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6226 - accuracy: 0.6484\n",
      "Epoch 285: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6085 - accuracy: 0.6586 - val_loss: 0.6103 - val_accuracy: 0.6915\n",
      "Epoch 286/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6238 - accuracy: 0.6406\n",
      "Epoch 286: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6131 - accuracy: 0.6613 - val_loss: 0.6095 - val_accuracy: 0.6809\n",
      "Epoch 287/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6400 - accuracy: 0.6250\n",
      "Epoch 287: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6153 - accuracy: 0.6694 - val_loss: 0.6087 - val_accuracy: 0.6809\n",
      "Epoch 288/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5926 - accuracy: 0.6797\n",
      "Epoch 288: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6221 - accuracy: 0.6505 - val_loss: 0.6082 - val_accuracy: 0.6915\n",
      "Epoch 289/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5659 - accuracy: 0.6953\n",
      "Epoch 289: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5958 - accuracy: 0.6720 - val_loss: 0.6076 - val_accuracy: 0.6809\n",
      "Epoch 290/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5848 - accuracy: 0.6875\n",
      "Epoch 290: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6237 - accuracy: 0.6452 - val_loss: 0.6077 - val_accuracy: 0.6809\n",
      "Epoch 291/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5794 - accuracy: 0.6875\n",
      "Epoch 291: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6096 - accuracy: 0.6559 - val_loss: 0.6083 - val_accuracy: 0.6809\n",
      "Epoch 292/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5994 - accuracy: 0.6328\n",
      "Epoch 292: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6133 - accuracy: 0.6505 - val_loss: 0.6093 - val_accuracy: 0.6915\n",
      "Epoch 293/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6423 - accuracy: 0.6172\n",
      "Epoch 293: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.6018 - accuracy: 0.6586 - val_loss: 0.6104 - val_accuracy: 0.6809\n",
      "Epoch 294/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6283 - accuracy: 0.6719\n",
      "Epoch 294: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6104 - accuracy: 0.6478 - val_loss: 0.6113 - val_accuracy: 0.6809\n",
      "Epoch 295/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6009 - accuracy: 0.6797\n",
      "Epoch 295: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6200 - accuracy: 0.6720 - val_loss: 0.6116 - val_accuracy: 0.6915\n",
      "Epoch 296/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5988 - accuracy: 0.6875\n",
      "Epoch 296: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6175 - accuracy: 0.6747 - val_loss: 0.6116 - val_accuracy: 0.6915\n",
      "Epoch 297/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6893 - accuracy: 0.6172\n",
      "Epoch 297: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.6301 - accuracy: 0.6559 - val_loss: 0.6109 - val_accuracy: 0.6915\n",
      "Epoch 298/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6254 - accuracy: 0.6250\n",
      "Epoch 298: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6067 - accuracy: 0.6532 - val_loss: 0.6097 - val_accuracy: 0.6809\n",
      "Epoch 299/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5743 - accuracy: 0.7188\n",
      "Epoch 299: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6109 - accuracy: 0.6694 - val_loss: 0.6084 - val_accuracy: 0.6809\n",
      "Epoch 300/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6145 - accuracy: 0.6641\n",
      "Epoch 300: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6207 - accuracy: 0.6478 - val_loss: 0.6083 - val_accuracy: 0.6702\n",
      "Epoch 301/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6205 - accuracy: 0.6562\n",
      "Epoch 301: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6139 - accuracy: 0.6720 - val_loss: 0.6080 - val_accuracy: 0.6809\n",
      "Epoch 302/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6346 - accuracy: 0.6562\n",
      "Epoch 302: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6124 - accuracy: 0.6478 - val_loss: 0.6076 - val_accuracy: 0.6809\n",
      "Epoch 303/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6016 - accuracy: 0.6641\n",
      "Epoch 303: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6134 - accuracy: 0.6720 - val_loss: 0.6072 - val_accuracy: 0.6702\n",
      "Epoch 304/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6000 - accuracy: 0.6875\n",
      "Epoch 304: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6200 - accuracy: 0.6640 - val_loss: 0.6070 - val_accuracy: 0.6809\n",
      "Epoch 305/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6447 - accuracy: 0.6406\n",
      "Epoch 305: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6242 - accuracy: 0.6532 - val_loss: 0.6076 - val_accuracy: 0.6915\n",
      "Epoch 306/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6600 - accuracy: 0.5938\n",
      "Epoch 306: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6241 - accuracy: 0.6452 - val_loss: 0.6084 - val_accuracy: 0.6915\n",
      "Epoch 307/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6232 - accuracy: 0.6641\n",
      "Epoch 307: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 190ms/step - loss: 0.6055 - accuracy: 0.6559 - val_loss: 0.6090 - val_accuracy: 0.6915\n",
      "Epoch 308/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6313 - accuracy: 0.6250\n",
      "Epoch 308: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6105 - accuracy: 0.6720 - val_loss: 0.6092 - val_accuracy: 0.6915\n",
      "Epoch 309/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6179 - accuracy: 0.6797\n",
      "Epoch 309: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6126 - accuracy: 0.6667 - val_loss: 0.6082 - val_accuracy: 0.6915\n",
      "Epoch 310/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6070 - accuracy: 0.6953\n",
      "Epoch 310: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6271 - accuracy: 0.6505 - val_loss: 0.6078 - val_accuracy: 0.6915\n",
      "Epoch 311/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5901 - accuracy: 0.6797\n",
      "Epoch 311: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6155 - accuracy: 0.6452 - val_loss: 0.6071 - val_accuracy: 0.6915\n",
      "Epoch 312/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6201 - accuracy: 0.6406\n",
      "Epoch 312: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6076 - accuracy: 0.6667 - val_loss: 0.6066 - val_accuracy: 0.7021\n",
      "Epoch 313/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5957 - accuracy: 0.6719\n",
      "Epoch 313: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6046 - accuracy: 0.6532 - val_loss: 0.6058 - val_accuracy: 0.7021\n",
      "Epoch 314/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6016 - accuracy: 0.6484\n",
      "Epoch 314: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6065 - accuracy: 0.6532 - val_loss: 0.6056 - val_accuracy: 0.7021\n",
      "Epoch 315/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5978 - accuracy: 0.6953\n",
      "Epoch 315: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6051 - accuracy: 0.6747 - val_loss: 0.6060 - val_accuracy: 0.6915\n",
      "Epoch 316/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6127 - accuracy: 0.6641\n",
      "Epoch 316: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6193 - accuracy: 0.6532 - val_loss: 0.6069 - val_accuracy: 0.6915\n",
      "Epoch 317/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6138 - accuracy: 0.6719\n",
      "Epoch 317: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6104 - accuracy: 0.6694 - val_loss: 0.6076 - val_accuracy: 0.6915\n",
      "Epoch 318/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5794 - accuracy: 0.6719\n",
      "Epoch 318: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6096 - accuracy: 0.6478 - val_loss: 0.6083 - val_accuracy: 0.6915\n",
      "Epoch 319/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6444 - accuracy: 0.6719\n",
      "Epoch 319: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6283 - accuracy: 0.6613 - val_loss: 0.6103 - val_accuracy: 0.6915\n",
      "Epoch 320/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6579 - accuracy: 0.6094\n",
      "Epoch 320: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6262 - accuracy: 0.6129 - val_loss: 0.6129 - val_accuracy: 0.7021\n",
      "Epoch 321/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6411 - accuracy: 0.6328\n",
      "Epoch 321: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6236 - accuracy: 0.6640 - val_loss: 0.6138 - val_accuracy: 0.7021\n",
      "Epoch 322/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6425 - accuracy: 0.6641\n",
      "Epoch 322: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6312 - accuracy: 0.6478 - val_loss: 0.6137 - val_accuracy: 0.7021\n",
      "Epoch 323/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5895 - accuracy: 0.6641\n",
      "Epoch 323: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6058 - accuracy: 0.6640 - val_loss: 0.6122 - val_accuracy: 0.7021\n",
      "Epoch 324/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5777 - accuracy: 0.6953\n",
      "Epoch 324: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6296 - accuracy: 0.6640 - val_loss: 0.6104 - val_accuracy: 0.6915\n",
      "Epoch 325/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5821 - accuracy: 0.7109\n",
      "Epoch 325: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6229 - accuracy: 0.6505 - val_loss: 0.6085 - val_accuracy: 0.6809\n",
      "Epoch 326/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6293 - accuracy: 0.6250\n",
      "Epoch 326: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6061 - accuracy: 0.6586 - val_loss: 0.6070 - val_accuracy: 0.6809\n",
      "Epoch 327/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6255 - accuracy: 0.6562\n",
      "Epoch 327: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5973 - accuracy: 0.6801 - val_loss: 0.6062 - val_accuracy: 0.6809\n",
      "Epoch 328/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6124 - accuracy: 0.6328\n",
      "Epoch 328: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6001 - accuracy: 0.6613 - val_loss: 0.6055 - val_accuracy: 0.6809\n",
      "Epoch 329/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6153 - accuracy: 0.6484\n",
      "Epoch 329: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5932 - accuracy: 0.6586 - val_loss: 0.6050 - val_accuracy: 0.6809\n",
      "Epoch 330/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5938 - accuracy: 0.6875\n",
      "Epoch 330: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5967 - accuracy: 0.6694 - val_loss: 0.6050 - val_accuracy: 0.6809\n",
      "Epoch 331/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6411 - accuracy: 0.5859\n",
      "Epoch 331: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6226 - accuracy: 0.6559 - val_loss: 0.6056 - val_accuracy: 0.6915\n",
      "Epoch 332/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6010 - accuracy: 0.6562\n",
      "Epoch 332: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.6136 - accuracy: 0.6667 - val_loss: 0.6060 - val_accuracy: 0.6915\n",
      "Epoch 333/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6241 - accuracy: 0.6250\n",
      "Epoch 333: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6152 - accuracy: 0.6532 - val_loss: 0.6077 - val_accuracy: 0.6915\n",
      "Epoch 334/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5919 - accuracy: 0.6875\n",
      "Epoch 334: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6211 - accuracy: 0.6398 - val_loss: 0.6086 - val_accuracy: 0.6915\n",
      "Epoch 335/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6040 - accuracy: 0.6523\n",
      "Epoch 335: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6062 - accuracy: 0.6532 - val_loss: 0.6101 - val_accuracy: 0.6915\n",
      "Epoch 336/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6096 - accuracy: 0.6484\n",
      "Epoch 336: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6141 - accuracy: 0.6532 - val_loss: 0.6114 - val_accuracy: 0.6915\n",
      "Epoch 337/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5733 - accuracy: 0.6953\n",
      "Epoch 337: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6149 - accuracy: 0.6694 - val_loss: 0.6114 - val_accuracy: 0.6915\n",
      "Epoch 338/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5878 - accuracy: 0.6953\n",
      "Epoch 338: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6125 - accuracy: 0.6505 - val_loss: 0.6118 - val_accuracy: 0.6915\n",
      "Epoch 339/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5960 - accuracy: 0.6641\n",
      "Epoch 339: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6076 - accuracy: 0.6478 - val_loss: 0.6119 - val_accuracy: 0.6915\n",
      "Epoch 340/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5996 - accuracy: 0.6953\n",
      "Epoch 340: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6159 - accuracy: 0.6640 - val_loss: 0.6103 - val_accuracy: 0.6915\n",
      "Epoch 341/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6127 - accuracy: 0.6641\n",
      "Epoch 341: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6236 - accuracy: 0.6478 - val_loss: 0.6083 - val_accuracy: 0.6809\n",
      "Epoch 342/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5710 - accuracy: 0.6875\n",
      "Epoch 342: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5986 - accuracy: 0.6747 - val_loss: 0.6061 - val_accuracy: 0.6702\n",
      "Epoch 343/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6130 - accuracy: 0.6562\n",
      "Epoch 343: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6172 - accuracy: 0.6478 - val_loss: 0.6051 - val_accuracy: 0.6809\n",
      "Epoch 344/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6113 - accuracy: 0.7031\n",
      "Epoch 344: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6068 - accuracy: 0.6694 - val_loss: 0.6055 - val_accuracy: 0.6809\n",
      "Epoch 345/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5792 - accuracy: 0.6719\n",
      "Epoch 345: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6000 - accuracy: 0.6586 - val_loss: 0.6061 - val_accuracy: 0.6702\n",
      "Epoch 346/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5930 - accuracy: 0.6641\n",
      "Epoch 346: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6039 - accuracy: 0.6613 - val_loss: 0.6068 - val_accuracy: 0.6809\n",
      "Epoch 347/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5988 - accuracy: 0.6953\n",
      "Epoch 347: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6129 - accuracy: 0.6559 - val_loss: 0.6069 - val_accuracy: 0.6809\n",
      "Epoch 348/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6357 - accuracy: 0.6641\n",
      "Epoch 348: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6039 - accuracy: 0.6694 - val_loss: 0.6060 - val_accuracy: 0.6809\n",
      "Epoch 349/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6463 - accuracy: 0.6250\n",
      "Epoch 349: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6076 - accuracy: 0.6720 - val_loss: 0.6049 - val_accuracy: 0.6809\n",
      "Epoch 350/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6011 - accuracy: 0.6875\n",
      "Epoch 350: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.6164 - accuracy: 0.6398 - val_loss: 0.6046 - val_accuracy: 0.6809\n",
      "Epoch 351/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6295 - accuracy: 0.6250\n",
      "Epoch 351: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.6191 - accuracy: 0.6478 - val_loss: 0.6053 - val_accuracy: 0.6915\n",
      "Epoch 352/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6344 - accuracy: 0.6172\n",
      "Epoch 352: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6026 - accuracy: 0.6720 - val_loss: 0.6060 - val_accuracy: 0.7021\n",
      "Epoch 353/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5769 - accuracy: 0.6562\n",
      "Epoch 353: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6037 - accuracy: 0.6559 - val_loss: 0.6066 - val_accuracy: 0.7021\n",
      "Epoch 354/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6248 - accuracy: 0.5781\n",
      "Epoch 354: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6274 - accuracy: 0.6183 - val_loss: 0.6065 - val_accuracy: 0.6809\n",
      "Epoch 355/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6466 - accuracy: 0.5781\n",
      "Epoch 355: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6206 - accuracy: 0.6290 - val_loss: 0.6062 - val_accuracy: 0.6809\n",
      "Epoch 356/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6038 - accuracy: 0.6953\n",
      "Epoch 356: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6129 - accuracy: 0.6586 - val_loss: 0.6058 - val_accuracy: 0.6915\n",
      "Epoch 357/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6236 - accuracy: 0.6172\n",
      "Epoch 357: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5957 - accuracy: 0.6774 - val_loss: 0.6052 - val_accuracy: 0.6809\n",
      "Epoch 358/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6413 - accuracy: 0.6484\n",
      "Epoch 358: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6265 - accuracy: 0.6613 - val_loss: 0.6054 - val_accuracy: 0.6809\n",
      "Epoch 359/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6324 - accuracy: 0.6719\n",
      "Epoch 359: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6105 - accuracy: 0.6586 - val_loss: 0.6061 - val_accuracy: 0.6809\n",
      "Epoch 360/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5838 - accuracy: 0.6641\n",
      "Epoch 360: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6060 - accuracy: 0.6559 - val_loss: 0.6070 - val_accuracy: 0.6702\n",
      "Epoch 361/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6535 - accuracy: 0.6094\n",
      "Epoch 361: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6087 - accuracy: 0.6640 - val_loss: 0.6078 - val_accuracy: 0.6915\n",
      "Epoch 362/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6039 - accuracy: 0.6719\n",
      "Epoch 362: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6073 - accuracy: 0.6532 - val_loss: 0.6085 - val_accuracy: 0.6809\n",
      "Epoch 363/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5807 - accuracy: 0.6875\n",
      "Epoch 363: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5968 - accuracy: 0.6694 - val_loss: 0.6079 - val_accuracy: 0.6915\n",
      "Epoch 364/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6049 - accuracy: 0.6328\n",
      "Epoch 364: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6134 - accuracy: 0.6478 - val_loss: 0.6084 - val_accuracy: 0.6915\n",
      "Epoch 365/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5952 - accuracy: 0.6406\n",
      "Epoch 365: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.6070 - accuracy: 0.6478 - val_loss: 0.6087 - val_accuracy: 0.6915\n",
      "Epoch 366/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5809 - accuracy: 0.6797\n",
      "Epoch 366: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.5997 - accuracy: 0.6559 - val_loss: 0.6095 - val_accuracy: 0.6915\n",
      "Epoch 367/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6246 - accuracy: 0.6484\n",
      "Epoch 367: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6112 - accuracy: 0.6452 - val_loss: 0.6096 - val_accuracy: 0.6915\n",
      "Epoch 368/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5834 - accuracy: 0.6875\n",
      "Epoch 368: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6044 - accuracy: 0.6613 - val_loss: 0.6093 - val_accuracy: 0.6915\n",
      "Epoch 369/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5706 - accuracy: 0.6875\n",
      "Epoch 369: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5831 - accuracy: 0.6801 - val_loss: 0.6086 - val_accuracy: 0.6915\n",
      "Epoch 370/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6046 - accuracy: 0.6797\n",
      "Epoch 370: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5947 - accuracy: 0.6774 - val_loss: 0.6071 - val_accuracy: 0.6915\n",
      "Epoch 371/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6012 - accuracy: 0.6719\n",
      "Epoch 371: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6123 - accuracy: 0.6694 - val_loss: 0.6066 - val_accuracy: 0.6915\n",
      "Epoch 372/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6172\n",
      "Epoch 372: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6304 - accuracy: 0.6344 - val_loss: 0.6076 - val_accuracy: 0.6915\n",
      "Epoch 373/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5974 - accuracy: 0.6875\n",
      "Epoch 373: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5959 - accuracy: 0.6747 - val_loss: 0.6091 - val_accuracy: 0.6915\n",
      "Epoch 374/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6119 - accuracy: 0.6719\n",
      "Epoch 374: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6143 - accuracy: 0.6398 - val_loss: 0.6099 - val_accuracy: 0.6915\n",
      "Epoch 375/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6152 - accuracy: 0.6562\n",
      "Epoch 375: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6187 - accuracy: 0.6532 - val_loss: 0.6101 - val_accuracy: 0.6915\n",
      "Epoch 376/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6014 - accuracy: 0.6562\n",
      "Epoch 376: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6155 - accuracy: 0.6478 - val_loss: 0.6088 - val_accuracy: 0.6915\n",
      "Epoch 377/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6231 - accuracy: 0.6250\n",
      "Epoch 377: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5998 - accuracy: 0.6559 - val_loss: 0.6063 - val_accuracy: 0.6809\n",
      "Epoch 378/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5969 - accuracy: 0.6250\n",
      "Epoch 378: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5897 - accuracy: 0.6559 - val_loss: 0.6051 - val_accuracy: 0.6809\n",
      "Epoch 379/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5637 - accuracy: 0.7031\n",
      "Epoch 379: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6037 - accuracy: 0.6559 - val_loss: 0.6048 - val_accuracy: 0.6809\n",
      "Epoch 380/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6157 - accuracy: 0.6641\n",
      "Epoch 380: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6128 - accuracy: 0.6613 - val_loss: 0.6059 - val_accuracy: 0.6809\n",
      "Epoch 381/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6004 - accuracy: 0.6953\n",
      "Epoch 381: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6178 - accuracy: 0.6586 - val_loss: 0.6075 - val_accuracy: 0.6809\n",
      "Epoch 382/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6023 - accuracy: 0.6641\n",
      "Epoch 382: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.5916 - accuracy: 0.6855 - val_loss: 0.6091 - val_accuracy: 0.6915\n",
      "Epoch 383/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6499 - accuracy: 0.5703\n",
      "Epoch 383: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6091 - accuracy: 0.6344 - val_loss: 0.6089 - val_accuracy: 0.6809\n",
      "Epoch 384/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6144 - accuracy: 0.6250\n",
      "Epoch 384: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6040 - accuracy: 0.6586 - val_loss: 0.6065 - val_accuracy: 0.7021\n",
      "Epoch 385/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6292 - accuracy: 0.6172\n",
      "Epoch 385: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6439 - accuracy: 0.6290 - val_loss: 0.6043 - val_accuracy: 0.6809\n",
      "Epoch 386/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6081 - accuracy: 0.6172\n",
      "Epoch 386: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5834 - accuracy: 0.6774 - val_loss: 0.6023 - val_accuracy: 0.6809\n",
      "Epoch 387/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5698 - accuracy: 0.6719\n",
      "Epoch 387: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6158 - accuracy: 0.6317 - val_loss: 0.6007 - val_accuracy: 0.6809\n",
      "Epoch 388/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6345 - accuracy: 0.6328\n",
      "Epoch 388: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6147 - accuracy: 0.6667 - val_loss: 0.6006 - val_accuracy: 0.6809\n",
      "Epoch 389/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5991 - accuracy: 0.6953\n",
      "Epoch 389: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6120 - accuracy: 0.6586 - val_loss: 0.6012 - val_accuracy: 0.6702\n",
      "Epoch 390/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6271 - accuracy: 0.6484\n",
      "Epoch 390: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5983 - accuracy: 0.6720 - val_loss: 0.6012 - val_accuracy: 0.6702\n",
      "Epoch 391/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6673 - accuracy: 0.6172\n",
      "Epoch 391: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6024 - accuracy: 0.6747 - val_loss: 0.6023 - val_accuracy: 0.6809\n",
      "Epoch 392/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6020 - accuracy: 0.6562\n",
      "Epoch 392: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5899 - accuracy: 0.6613 - val_loss: 0.6027 - val_accuracy: 0.6915\n",
      "Epoch 393/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6377 - accuracy: 0.6328\n",
      "Epoch 393: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6152 - accuracy: 0.6505 - val_loss: 0.6020 - val_accuracy: 0.6809\n",
      "Epoch 394/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6052 - accuracy: 0.7031\n",
      "Epoch 394: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6338 - accuracy: 0.6801 - val_loss: 0.6017 - val_accuracy: 0.6809\n",
      "Epoch 395/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6070 - accuracy: 0.6719\n",
      "Epoch 395: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6003 - accuracy: 0.6747 - val_loss: 0.6028 - val_accuracy: 0.6702\n",
      "Epoch 396/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5819 - accuracy: 0.6719\n",
      "Epoch 396: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5952 - accuracy: 0.6801 - val_loss: 0.6026 - val_accuracy: 0.6809\n",
      "Epoch 397/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5936 - accuracy: 0.6875\n",
      "Epoch 397: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.5962 - accuracy: 0.6667 - val_loss: 0.6021 - val_accuracy: 0.6915\n",
      "Epoch 398/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5770 - accuracy: 0.6797\n",
      "Epoch 398: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6000 - accuracy: 0.6640 - val_loss: 0.6019 - val_accuracy: 0.6915\n",
      "Epoch 399/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5923 - accuracy: 0.6641\n",
      "Epoch 399: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6067 - accuracy: 0.6586 - val_loss: 0.6015 - val_accuracy: 0.6915\n",
      "Epoch 400/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6070 - accuracy: 0.6875\n",
      "Epoch 400: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6304 - accuracy: 0.6613 - val_loss: 0.6014 - val_accuracy: 0.6809\n",
      "Epoch 401/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6049 - accuracy: 0.6250\n",
      "Epoch 401: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6018 - accuracy: 0.6452 - val_loss: 0.6023 - val_accuracy: 0.6809\n",
      "Epoch 402/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5842 - accuracy: 0.7344\n",
      "Epoch 402: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6088 - accuracy: 0.6613 - val_loss: 0.6026 - val_accuracy: 0.6809\n",
      "Epoch 403/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5964 - accuracy: 0.6797\n",
      "Epoch 403: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6197 - accuracy: 0.6425 - val_loss: 0.6034 - val_accuracy: 0.6915\n",
      "Epoch 404/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5669 - accuracy: 0.7188\n",
      "Epoch 404: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6051 - accuracy: 0.6505 - val_loss: 0.6038 - val_accuracy: 0.6809\n",
      "Epoch 405/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6059 - accuracy: 0.6641\n",
      "Epoch 405: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6062 - accuracy: 0.6478 - val_loss: 0.6039 - val_accuracy: 0.6809\n",
      "Epoch 406/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6240 - accuracy: 0.6172\n",
      "Epoch 406: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6036 - accuracy: 0.6694 - val_loss: 0.6034 - val_accuracy: 0.6809\n",
      "Epoch 407/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6751 - accuracy: 0.6406\n",
      "Epoch 407: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6333 - accuracy: 0.6505 - val_loss: 0.6026 - val_accuracy: 0.6809\n",
      "Epoch 408/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6135 - accuracy: 0.6094\n",
      "Epoch 408: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6135 - accuracy: 0.6586 - val_loss: 0.6026 - val_accuracy: 0.6915\n",
      "Epoch 409/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6162 - accuracy: 0.6641\n",
      "Epoch 409: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6143 - accuracy: 0.6398 - val_loss: 0.6037 - val_accuracy: 0.7021\n",
      "Epoch 410/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5795 - accuracy: 0.6641\n",
      "Epoch 410: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5985 - accuracy: 0.6640 - val_loss: 0.6045 - val_accuracy: 0.7021\n",
      "Epoch 411/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6492 - accuracy: 0.5938\n",
      "Epoch 411: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6185 - accuracy: 0.6317 - val_loss: 0.6053 - val_accuracy: 0.7021\n",
      "Epoch 412/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5987 - accuracy: 0.6328\n",
      "Epoch 412: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6161 - accuracy: 0.6505 - val_loss: 0.6052 - val_accuracy: 0.7021\n",
      "Epoch 413/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5510 - accuracy: 0.7422\n",
      "Epoch 413: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5975 - accuracy: 0.6962 - val_loss: 0.6051 - val_accuracy: 0.6809\n",
      "Epoch 414/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6647 - accuracy: 0.6328\n",
      "Epoch 414: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6003 - accuracy: 0.6774 - val_loss: 0.6035 - val_accuracy: 0.6809\n",
      "Epoch 415/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6112 - accuracy: 0.6172\n",
      "Epoch 415: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5932 - accuracy: 0.6613 - val_loss: 0.6027 - val_accuracy: 0.6809\n",
      "Epoch 416/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6157 - accuracy: 0.6484\n",
      "Epoch 416: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5985 - accuracy: 0.6801 - val_loss: 0.6029 - val_accuracy: 0.6915\n",
      "Epoch 417/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6381 - accuracy: 0.6406\n",
      "Epoch 417: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6165 - accuracy: 0.6425 - val_loss: 0.6030 - val_accuracy: 0.7021\n",
      "Epoch 418/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5847 - accuracy: 0.6641\n",
      "Epoch 418: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5844 - accuracy: 0.6667 - val_loss: 0.6029 - val_accuracy: 0.7021\n",
      "Epoch 419/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6063 - accuracy: 0.6641\n",
      "Epoch 419: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6035 - accuracy: 0.6694 - val_loss: 0.6027 - val_accuracy: 0.7021\n",
      "Epoch 420/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5743 - accuracy: 0.7188\n",
      "Epoch 420: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6047 - accuracy: 0.6532 - val_loss: 0.6027 - val_accuracy: 0.7021\n",
      "Epoch 421/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5707 - accuracy: 0.6875\n",
      "Epoch 421: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6039 - accuracy: 0.6586 - val_loss: 0.6032 - val_accuracy: 0.7021\n",
      "Epoch 422/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6537 - accuracy: 0.6328\n",
      "Epoch 422: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6157 - accuracy: 0.6667 - val_loss: 0.6030 - val_accuracy: 0.7021\n",
      "Epoch 423/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6286 - accuracy: 0.6406\n",
      "Epoch 423: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6093 - accuracy: 0.6505 - val_loss: 0.6027 - val_accuracy: 0.7021\n",
      "Epoch 424/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5801 - accuracy: 0.7031\n",
      "Epoch 424: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5942 - accuracy: 0.6640 - val_loss: 0.6021 - val_accuracy: 0.7021\n",
      "Epoch 425/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5712 - accuracy: 0.7031\n",
      "Epoch 425: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5885 - accuracy: 0.6640 - val_loss: 0.6013 - val_accuracy: 0.6915\n",
      "Epoch 426/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5971 - accuracy: 0.6094\n",
      "Epoch 426: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5871 - accuracy: 0.6505 - val_loss: 0.6003 - val_accuracy: 0.6915\n",
      "Epoch 427/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5933 - accuracy: 0.6719\n",
      "Epoch 427: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6044 - accuracy: 0.6640 - val_loss: 0.6002 - val_accuracy: 0.6915\n",
      "Epoch 428/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5855 - accuracy: 0.6719\n",
      "Epoch 428: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5994 - accuracy: 0.6586 - val_loss: 0.6004 - val_accuracy: 0.6915\n",
      "Epoch 429/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6155 - accuracy: 0.6172\n",
      "Epoch 429: val_accuracy did not improve from 0.70213\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6101 - accuracy: 0.6398 - val_loss: 0.6010 - val_accuracy: 0.7021\n",
      "Epoch 430/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5824 - accuracy: 0.6719\n",
      "Epoch 430: val_accuracy improved from 0.70213 to 0.71277, saving model to .\\SIN492-0430.hdf5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.5925 - accuracy: 0.6586 - val_loss: 0.6019 - val_accuracy: 0.7128\n",
      "Epoch 431/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5839 - accuracy: 0.6406\n",
      "Epoch 431: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5922 - accuracy: 0.6640 - val_loss: 0.6028 - val_accuracy: 0.7128\n",
      "Epoch 432/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6347 - accuracy: 0.6641\n",
      "Epoch 432: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6051 - accuracy: 0.6720 - val_loss: 0.6032 - val_accuracy: 0.7128\n",
      "Epoch 433/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6251 - accuracy: 0.6641\n",
      "Epoch 433: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6193 - accuracy: 0.6720 - val_loss: 0.6032 - val_accuracy: 0.7021\n",
      "Epoch 434/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6232 - accuracy: 0.5859\n",
      "Epoch 434: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6013 - accuracy: 0.6613 - val_loss: 0.6031 - val_accuracy: 0.7128\n",
      "Epoch 435/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6090 - accuracy: 0.6484\n",
      "Epoch 435: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6022 - accuracy: 0.6613 - val_loss: 0.6019 - val_accuracy: 0.7021\n",
      "Epoch 436/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5994 - accuracy: 0.6484\n",
      "Epoch 436: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6016 - accuracy: 0.6559 - val_loss: 0.6013 - val_accuracy: 0.6915\n",
      "Epoch 437/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5689 - accuracy: 0.6875\n",
      "Epoch 437: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5912 - accuracy: 0.6640 - val_loss: 0.6012 - val_accuracy: 0.6915\n",
      "Epoch 438/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6198 - accuracy: 0.6562\n",
      "Epoch 438: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6158 - accuracy: 0.6532 - val_loss: 0.6006 - val_accuracy: 0.6915\n",
      "Epoch 439/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6028 - accuracy: 0.6719\n",
      "Epoch 439: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6032 - accuracy: 0.6640 - val_loss: 0.6003 - val_accuracy: 0.6915\n",
      "Epoch 440/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6225 - accuracy: 0.6484\n",
      "Epoch 440: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6116 - accuracy: 0.6747 - val_loss: 0.6005 - val_accuracy: 0.6915\n",
      "Epoch 441/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5592 - accuracy: 0.7422\n",
      "Epoch 441: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6018 - accuracy: 0.6667 - val_loss: 0.6016 - val_accuracy: 0.6915\n",
      "Epoch 442/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6397 - accuracy: 0.6250\n",
      "Epoch 442: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5950 - accuracy: 0.6694 - val_loss: 0.6026 - val_accuracy: 0.7128\n",
      "Epoch 443/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5553 - accuracy: 0.7422\n",
      "Epoch 443: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5935 - accuracy: 0.6882 - val_loss: 0.6025 - val_accuracy: 0.7128\n",
      "Epoch 444/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5699 - accuracy: 0.7109\n",
      "Epoch 444: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5903 - accuracy: 0.6855 - val_loss: 0.6015 - val_accuracy: 0.7021\n",
      "Epoch 445/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6096 - accuracy: 0.6562\n",
      "Epoch 445: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.6023 - accuracy: 0.6720 - val_loss: 0.6016 - val_accuracy: 0.7021\n",
      "Epoch 446/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5667 - accuracy: 0.7109\n",
      "Epoch 446: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6038 - accuracy: 0.6532 - val_loss: 0.6003 - val_accuracy: 0.7021\n",
      "Epoch 447/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5957 - accuracy: 0.6562\n",
      "Epoch 447: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.5930 - accuracy: 0.6828 - val_loss: 0.5996 - val_accuracy: 0.6915\n",
      "Epoch 448/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5801 - accuracy: 0.6875\n",
      "Epoch 448: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6020 - accuracy: 0.6774 - val_loss: 0.6000 - val_accuracy: 0.6915\n",
      "Epoch 449/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6129 - accuracy: 0.5859\n",
      "Epoch 449: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6095 - accuracy: 0.6505 - val_loss: 0.6007 - val_accuracy: 0.6915\n",
      "Epoch 450/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6513 - accuracy: 0.6484\n",
      "Epoch 450: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6177 - accuracy: 0.6559 - val_loss: 0.6015 - val_accuracy: 0.6915\n",
      "Epoch 451/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6208 - accuracy: 0.6484\n",
      "Epoch 451: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6081 - accuracy: 0.6586 - val_loss: 0.6031 - val_accuracy: 0.7021\n",
      "Epoch 452/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5992 - accuracy: 0.6719\n",
      "Epoch 452: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6124 - accuracy: 0.6505 - val_loss: 0.6044 - val_accuracy: 0.7021\n",
      "Epoch 453/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6023 - accuracy: 0.6406\n",
      "Epoch 453: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6108 - accuracy: 0.6425 - val_loss: 0.6040 - val_accuracy: 0.7021\n",
      "Epoch 454/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5981 - accuracy: 0.6719\n",
      "Epoch 454: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5907 - accuracy: 0.6667 - val_loss: 0.6027 - val_accuracy: 0.6915\n",
      "Epoch 455/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5977 - accuracy: 0.6484\n",
      "Epoch 455: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5996 - accuracy: 0.6640 - val_loss: 0.6004 - val_accuracy: 0.6915\n",
      "Epoch 456/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5774 - accuracy: 0.6641\n",
      "Epoch 456: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5884 - accuracy: 0.6774 - val_loss: 0.5986 - val_accuracy: 0.6915\n",
      "Epoch 457/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6255 - accuracy: 0.6719\n",
      "Epoch 457: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6282 - accuracy: 0.6747 - val_loss: 0.5980 - val_accuracy: 0.6809\n",
      "Epoch 458/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6185 - accuracy: 0.6328\n",
      "Epoch 458: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6026 - accuracy: 0.6532 - val_loss: 0.5979 - val_accuracy: 0.6809\n",
      "Epoch 459/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6079 - accuracy: 0.6953\n",
      "Epoch 459: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.5991 - accuracy: 0.6909 - val_loss: 0.5991 - val_accuracy: 0.6915\n",
      "Epoch 460/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6638 - accuracy: 0.6172\n",
      "Epoch 460: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6024 - accuracy: 0.6640 - val_loss: 0.6000 - val_accuracy: 0.6809\n",
      "Epoch 461/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5960 - accuracy: 0.6641\n",
      "Epoch 461: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5959 - accuracy: 0.6586 - val_loss: 0.6005 - val_accuracy: 0.6915\n",
      "Epoch 462/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6205 - accuracy: 0.6484\n",
      "Epoch 462: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6088 - accuracy: 0.6694 - val_loss: 0.5997 - val_accuracy: 0.6915\n",
      "Epoch 463/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6596 - accuracy: 0.5781\n",
      "Epoch 463: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6090 - accuracy: 0.6452 - val_loss: 0.6001 - val_accuracy: 0.7128\n",
      "Epoch 464/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5670 - accuracy: 0.6719\n",
      "Epoch 464: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5940 - accuracy: 0.6532 - val_loss: 0.5989 - val_accuracy: 0.7128\n",
      "Epoch 465/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6406 - accuracy: 0.5781\n",
      "Epoch 465: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6122 - accuracy: 0.6586 - val_loss: 0.5980 - val_accuracy: 0.7128\n",
      "Epoch 466/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6151 - accuracy: 0.6875\n",
      "Epoch 466: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6038 - accuracy: 0.6613 - val_loss: 0.5977 - val_accuracy: 0.6915\n",
      "Epoch 467/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6210 - accuracy: 0.6016\n",
      "Epoch 467: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5828 - accuracy: 0.6586 - val_loss: 0.5978 - val_accuracy: 0.6915\n",
      "Epoch 468/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5833 - accuracy: 0.6875\n",
      "Epoch 468: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6010 - accuracy: 0.6801 - val_loss: 0.5968 - val_accuracy: 0.7128\n",
      "Epoch 469/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5603 - accuracy: 0.7109\n",
      "Epoch 469: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5974 - accuracy: 0.6640 - val_loss: 0.5974 - val_accuracy: 0.7128\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6425\n",
      "Epoch 470: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.6076 - accuracy: 0.6425 - val_loss: 0.5983 - val_accuracy: 0.7128\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5977 - accuracy: 0.6694\n",
      "Epoch 471: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.5977 - accuracy: 0.6694 - val_loss: 0.5985 - val_accuracy: 0.7021\n",
      "Epoch 472/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6136 - accuracy: 0.6406\n",
      "Epoch 472: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5959 - accuracy: 0.6640 - val_loss: 0.5973 - val_accuracy: 0.7021\n",
      "Epoch 473/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5860 - accuracy: 0.6875\n",
      "Epoch 473: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5787 - accuracy: 0.6989 - val_loss: 0.5969 - val_accuracy: 0.6809\n",
      "Epoch 474/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5862 - accuracy: 0.6562\n",
      "Epoch 474: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5938 - accuracy: 0.6747 - val_loss: 0.5974 - val_accuracy: 0.6915\n",
      "Epoch 475/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5866 - accuracy: 0.6875\n",
      "Epoch 475: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6061 - accuracy: 0.6640 - val_loss: 0.5975 - val_accuracy: 0.6915\n",
      "Epoch 476/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5544 - accuracy: 0.7188\n",
      "Epoch 476: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5915 - accuracy: 0.6828 - val_loss: 0.5972 - val_accuracy: 0.6915\n",
      "Epoch 477/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6174 - accuracy: 0.6641\n",
      "Epoch 477: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5909 - accuracy: 0.6962 - val_loss: 0.5982 - val_accuracy: 0.7128\n",
      "Epoch 478/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6184 - accuracy: 0.6250\n",
      "Epoch 478: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5972 - accuracy: 0.6559 - val_loss: 0.5985 - val_accuracy: 0.7021\n",
      "Epoch 479/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5787 - accuracy: 0.6719\n",
      "Epoch 479: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5819 - accuracy: 0.6962 - val_loss: 0.5987 - val_accuracy: 0.7128\n",
      "Epoch 480/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6017 - accuracy: 0.6562\n",
      "Epoch 480: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5910 - accuracy: 0.6801 - val_loss: 0.5979 - val_accuracy: 0.7021\n",
      "Epoch 481/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6470 - accuracy: 0.5781\n",
      "Epoch 481: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5916 - accuracy: 0.6694 - val_loss: 0.5959 - val_accuracy: 0.6915\n",
      "Epoch 482/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5876 - accuracy: 0.7266\n",
      "Epoch 482: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5897 - accuracy: 0.6855 - val_loss: 0.5937 - val_accuracy: 0.6915\n",
      "Epoch 483/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6437 - accuracy: 0.5938\n",
      "Epoch 483: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.6130 - accuracy: 0.6586 - val_loss: 0.5950 - val_accuracy: 0.6915\n",
      "Epoch 484/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5745 - accuracy: 0.6562\n",
      "Epoch 484: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5825 - accuracy: 0.6505 - val_loss: 0.5974 - val_accuracy: 0.7021\n",
      "Epoch 485/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6414 - accuracy: 0.5938\n",
      "Epoch 485: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5866 - accuracy: 0.6747 - val_loss: 0.5988 - val_accuracy: 0.7021\n",
      "Epoch 486/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5692 - accuracy: 0.6797\n",
      "Epoch 486: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.6056 - accuracy: 0.6532 - val_loss: 0.5990 - val_accuracy: 0.7021\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.6720\n",
      "Epoch 487: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 214ms/step - loss: 0.6053 - accuracy: 0.6720 - val_loss: 0.5991 - val_accuracy: 0.6809\n",
      "Epoch 488/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6129 - accuracy: 0.7188\n",
      "Epoch 488: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6003 - accuracy: 0.6828 - val_loss: 0.5982 - val_accuracy: 0.7021\n",
      "Epoch 489/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5916 - accuracy: 0.6406\n",
      "Epoch 489: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5969 - accuracy: 0.6694 - val_loss: 0.5972 - val_accuracy: 0.7128\n",
      "Epoch 490/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5733 - accuracy: 0.6562\n",
      "Epoch 490: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5933 - accuracy: 0.6425 - val_loss: 0.5966 - val_accuracy: 0.7021\n",
      "Epoch 491/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5755 - accuracy: 0.7031\n",
      "Epoch 491: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5942 - accuracy: 0.6640 - val_loss: 0.5961 - val_accuracy: 0.6915\n",
      "Epoch 492/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5957 - accuracy: 0.6641\n",
      "Epoch 492: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6120 - accuracy: 0.6559 - val_loss: 0.5963 - val_accuracy: 0.6915\n",
      "Epoch 493/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6092 - accuracy: 0.6875\n",
      "Epoch 493: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6031 - accuracy: 0.6828 - val_loss: 0.5965 - val_accuracy: 0.7021\n",
      "Epoch 494/500\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.6050 - accuracy: 0.6836\n",
      "Epoch 494: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.5989 - accuracy: 0.6640 - val_loss: 0.5978 - val_accuracy: 0.6915\n",
      "Epoch 495/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5538 - accuracy: 0.7344\n",
      "Epoch 495: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.5984 - accuracy: 0.6801 - val_loss: 0.5993 - val_accuracy: 0.7128\n",
      "Epoch 496/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5676 - accuracy: 0.6953\n",
      "Epoch 496: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5911 - accuracy: 0.6828 - val_loss: 0.5995 - val_accuracy: 0.7021\n",
      "Epoch 497/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5989 - accuracy: 0.6641\n",
      "Epoch 497: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6091 - accuracy: 0.6505 - val_loss: 0.5992 - val_accuracy: 0.6809\n",
      "Epoch 498/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6227 - accuracy: 0.6484\n",
      "Epoch 498: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6214 - accuracy: 0.6425 - val_loss: 0.5971 - val_accuracy: 0.6915\n",
      "Epoch 499/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6443 - accuracy: 0.6562\n",
      "Epoch 499: val_accuracy did not improve from 0.71277\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5990 - accuracy: 0.6882 - val_loss: 0.5955 - val_accuracy: 0.7021\n",
      "Epoch 500/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6307 - accuracy: 0.6406\n",
      "Epoch 500: val_accuracy improved from 0.71277 to 0.72340, saving model to .\\SIN492-0500.hdf5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6066 - accuracy: 0.6586 - val_loss: 0.5947 - val_accuracy: 0.7234\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(entradasTrain, valoresSaidaTrain, epochs=500, batch_size=128,  callbacks=[cp_callback],validation_data=(entradasTest, valoresSaidaTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811d7db-11d0-4ada-b156-12d54248840f",
   "metadata": {},
   "source": [
    "# Salvar o modelo inteiro com SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1eb47fa2-5043-4047-94a5-1f40e424ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\maste\\Videos\\Modelo-MLP\\patch_model_sin492\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\maste\\Videos\\Modelo-MLP\\patch_model_sin492\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\maste\\Videos\\Modelo-MLP\\patch_model_sin492 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'patch_model_sin492'\n",
    "save_dir = save_dir = 'C:\\\\Users\\\\maste\\\\Videos\\\\Modelo-MLP'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b5e17-143b-4b1c-8880-79ce1589587b",
   "metadata": {},
   "source": [
    "# Leitura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c769a31d-29b2-4b1a-9bbe-2ca8911eb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "# Carregar modelo de arquivo\n",
    "# Carregar modelo de arquivo\n",
    "model = tf.keras.models.load_model(\"C:\\\\Users\\\\maste\\\\Videos\\\\Modelo-MLP\\\\patch_model_sin492\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f09953a-b35b-411c-b0d1-f1aae34689ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 32)                512       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673 (2.63 KB)\n",
      "Trainable params: 609 (2.38 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregar os pesos do modelo\n",
    "model.load_weights(\"C:\\\\Users\\\\maste\\\\Videos\\\\Modelo-MLP\\\\SIN492-0500.hdf5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88916592-552e-49fa-a854-fdb0efffda96",
   "metadata": {},
   "source": [
    "# Leitura CPKPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "760c2009-c9a7-47de-9605-12e379a74b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---train\n",
      "12/12 - 1s - loss: 0.5733 - accuracy: 0.7124 - 629ms/epoch - 52ms/step\n",
      "0.5733437538146973\n",
      "0.7123655676841736\n",
      "Restored model teste, accuracy: 71.24%\n",
      "---teste\n",
      "3/3 - 0s - loss: 0.5947 - accuracy: 0.7234 - 49ms/epoch - 16ms/step\n",
      "0.594719648361206\n",
      "0.7234042286872864\n",
      "Restored model teste, accuracy: 72.34%\n"
     ]
    }
   ],
   "source": [
    "print(\"---train\")\n",
    "loss, acc = model.evaluate( entradasTrain,valoresSaidaTrain, verbose=2)\n",
    "print(loss)\n",
    "print(acc)\n",
    "print(\"Restored model teste, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "print(\"---teste\")\n",
    "loss, acc = model.evaluate( entradasTest,valoresSaidaTest, verbose=2)\n",
    "print(loss)\n",
    "print(acc)\n",
    "print(\"Restored model teste, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7e21b-244e-4e9f-8829-8eaf7a503dbe",
   "metadata": {},
   "source": [
    "# Gráfico da Acurácia por épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0380fca-4982-4521-a7d2-e4bb0c64e7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Acurácia por épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26857f4-f5f0-4636-8721-cfaf6b453eb3",
   "metadata": {},
   "source": [
    "# Gráfico Loss por épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8095184a-eaf4-4879-bade-cb89bc4238cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2662bbe9410>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss por épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Treino', 'Validação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283ef4e-052f-417f-8c99-f71ab375fb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
